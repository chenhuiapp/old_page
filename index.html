<!DOCTYPE html>
<head><meta charset="utf-8" /><meta content="minimum-scale=1, initial-scale=1, width=device-width, shrink-to-fit=no" name="viewport" /><link href="/static/css/style.css" rel="stylesheet" type="text/css" /><link href="/static/img/logo.png" rel="shortcut icon" type="image/png" /><link href="/static/img/logo.png" rel="shortcut icon" sizes="192x192" /><link href="/static/img/logo.png" rel="apple-touch-icon" /><meta name="apple-mobile-web-app-title" /><meta content="yes" name="apple-mobile-web-app-capable" /><meta content="yes" name="apple-touch-fullscreen" /><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style" /><meta content="yes" name="mobile-web-app-capable" /><meta property="og:title" /><meta content="site" property="og:type" /><meta content="/static/img/logo.png" property="og:image" /><meta property="og:description" /><title></title><meta property="og:site_name" /><meta /></head><body><div id="root"></div><script>window.logseq_db="[&quot;~#datascript/DB&quot;,[&quot;^ &quot;,&quot;~:schema&quot;,[&quot;^ &quot;,&quot;~:db/encryption-keys&quot;,[&quot;^ &quot;],&quot;~:file/content&quot;,[&quot;^ &quot;],&quot;~:git/status&quot;,[&quot;^ &quot;],&quot;~:repo/cloned?&quot;,[&quot;^ &quot;],&quot;~:block/alias&quot;,[&quot;^ &quot;,&quot;~:db/valueType&quot;,&quot;~:db.type/ref&quot;,&quot;~:db/cardinality&quot;,&quot;~:db.cardinality/many&quot;],&quot;~:git/error&quot;,[&quot;^ &quot;],&quot;~:block/pre-block?&quot;,[&quot;^ &quot;],&quot;~:git/last-pulled-at&quot;,[&quot;^ &quot;],&quot;~:block/uuid&quot;,[&quot;^ &quot;,&quot;~:db/unique&quot;,&quot;~:db.unique/identity&quot;],&quot;~:repo/url&quot;,[&quot;^ &quot;,&quot;^?&quot;,&quot;^@&quot;],&quot;~:block/priority&quot;,[&quot;^ &quot;],&quot;~:block/properties&quot;,[&quot;^ &quot;],&quot;~:block/journal?&quot;,[&quot;^ &quot;],&quot;~:block/updated-at&quot;,[&quot;^ &quot;],&quot;~:block/repeated?&quot;,[&quot;^ &quot;],&quot;~:db/type&quot;,[&quot;^ &quot;],&quot;~:file/handle&quot;,[&quot;^ &quot;],&quot;~:block/left&quot;,[&quot;^ &quot;,&quot;^7&quot;,&quot;^8&quot;],&quot;~:block/refs&quot;,[&quot;^ &quot;,&quot;^7&quot;,&quot;^8&quot;,&quot;^9&quot;,&quot;^:&quot;],&quot;~:block/scheduled&quot;,[&quot;^ &quot;],&quot;~:me/avatar&quot;,[&quot;^ &quot;],&quot;~:db/encrypted?&quot;,[&quot;^ &quot;],&quot;~:block/created-at&quot;,[&quot;^ &quot;],&quot;~:block/deadline&quot;,[&quot;^ &quot;],&quot;~:block/body&quot;,[&quot;^ &quot;],&quot;~:me/name&quot;,[&quot;^ &quot;],&quot;~:block/meta&quot;,[&quot;^ &quot;],&quot;~:block/journal-day&quot;,[&quot;^ &quot;],&quot;~:block/format&quot;,[&quot;^ &quot;],&quot;~:block/level&quot;,[&quot;^ &quot;],&quot;~:block/tags&quot;,[&quot;^ &quot;,&quot;^7&quot;,&quot;^8&quot;,&quot;^9&quot;,&quot;^:&quot;],&quot;~:block/title&quot;,[&quot;^ &quot;],&quot;~:block/content&quot;,[&quot;^ &quot;],&quot;~:recent/pages&quot;,[&quot;^ &quot;],&quot;~:db/ident&quot;,[&quot;^ &quot;,&quot;^?&quot;,&quot;^@&quot;],&quot;~:block/path-refs&quot;,[&quot;^ &quot;,&quot;^7&quot;,&quot;^8&quot;,&quot;^9&quot;,&quot;^:&quot;],&quot;~:block/parent&quot;,[&quot;^ &quot;,&quot;^7&quot;,&quot;^8&quot;],&quot;~:block/type&quot;,[&quot;^ &quot;],&quot;~:me/email&quot;,[&quot;^ &quot;],&quot;~:block/page&quot;,[&quot;^ &quot;,&quot;^7&quot;,&quot;^8&quot;,&quot;~:db/index&quot;,true],&quot;~:block/name&quot;,[&quot;^ &quot;,&quot;^?&quot;,&quot;^@&quot;],&quot;~:file/path&quot;,[&quot;^ &quot;,&quot;^?&quot;,&quot;^@&quot;],&quot;~:block/file&quot;,[&quot;^ &quot;,&quot;^7&quot;,&quot;^8&quot;],&quot;~:block/marker&quot;,[&quot;^ &quot;],&quot;~:block/original-name&quot;,[&quot;^ &quot;,&quot;^?&quot;,&quot;^@&quot;],&quot;~:schema/version&quot;,[&quot;^ &quot;]],&quot;~:datoms&quot;,[&quot;~#list&quot;,[[&quot;~#datascript/Datom&quot;,[1,&quot;^1:&quot;,&quot;0.0.2&quot;,536870913]],[&quot;^1=&quot;,[23,&quot;^D&quot;,false,536870917]],[&quot;^1=&quot;,[23,&quot;^15&quot;,&quot;agent&quot;,536870917]],[&quot;^1=&quot;,[23,&quot;^19&quot;,&quot;Agent&quot;,536870917]],[&quot;^1=&quot;,[23,&quot;^C&quot;,[&quot;^ &quot;,&quot;~:public&quot;,true],536870971]],[&quot;^1=&quot;,[23,&quot;^&gt;&quot;,&quot;~u60bab449-88a2-439a-b020-21819d9ee247&quot;,536870917]],[&quot;^1=&quot;,[24,&quot;^D&quot;,false,536870917]],[&quot;^1=&quot;,[24,&quot;^15&quot;,&quot;index&quot;,536870917]],[&quot;^1=&quot;,[24,&quot;^19&quot;,&quot;Index&quot;,536870917]],[&quot;^1=&quot;,[24,&quot;^C&quot;,[&quot;^ &quot;,&quot;^1&gt;&quot;,true],536870961]],[&quot;^1=&quot;,[24,&quot;^&gt;&quot;,&quot;~u60bab449-22df-4cee-9df0-c91fd2567e92&quot;,536870917]],[&quot;^1=&quot;,[34,&quot;^D&quot;,false,536870917]],[&quot;^1=&quot;,[34,&quot;^15&quot;,&quot;environment&quot;,536870917]],[&quot;^1=&quot;,[34,&quot;^19&quot;,&quot;Environment&quot;,536870917]],[&quot;^1=&quot;,[34,&quot;^C&quot;,[&quot;^ &quot;,&quot;^1&gt;&quot;,true],536870976]],[&quot;^1=&quot;,[34,&quot;^&gt;&quot;,&quot;~u60bab449-4179-4876-aeb2-61f1e94b8da8&quot;,536870917]],[&quot;^1=&quot;,[35,&quot;^D&quot;,false,536870917]],[&quot;^1=&quot;,[35,&quot;^15&quot;,&quot;reinforcement learning&quot;,536870917]],[&quot;^1=&quot;,[35,&quot;^19&quot;,&quot;Reinforcement Learning&quot;,536870917]],[&quot;^1=&quot;,[35,&quot;^C&quot;,[&quot;^ &quot;,&quot;^1&gt;&quot;,true],536870966]],[&quot;^1=&quot;,[35,&quot;^&gt;&quot;,&quot;~u60bab449-f785-4c4e-a44c-1fd27f15868d&quot;,536870917]],[&quot;^1=&quot;,[45,&quot;~:block/anchor&quot;,&quot;&quot;,536870917]],[&quot;^1=&quot;,[45,&quot;^P&quot;,[],536870960]],[&quot;^1=&quot;,[45,&quot;~:block/children&quot;,[&quot;~#set&quot;,[]],536870917]],[&quot;^1=&quot;,[45,&quot;^X&quot;,&quot;[[Reinforcement Learning]]&quot;,536870917]],[&quot;^1=&quot;,[45,&quot;^T&quot;,&quot;~:markdown&quot;,536870917]],[&quot;^1=&quot;,[45,&quot;^I&quot;,101,536870960]],[&quot;^1=&quot;,[45,&quot;^U&quot;,1,536870960]],[&quot;^1=&quot;,[45,&quot;^R&quot;,[&quot;^ &quot;,&quot;~:timestamps&quot;,[],&quot;~:properties&quot;,[],&quot;~:start-pos&quot;,0,&quot;~:end-pos&quot;,29],536870917]],[&quot;^1=&quot;,[45,&quot;^13&quot;,24,536870917]],[&quot;^1=&quot;,[45,&quot;^10&quot;,24,536870917]],[&quot;^1=&quot;,[45,&quot;^[&quot;,35,536870960]],[&quot;^1=&quot;,[45,&quot;^J&quot;,35,536870960]],[&quot;^1=&quot;,[45,&quot;^W&quot;,[[&quot;Link&quot;,[&quot;^ &quot;,&quot;~:url&quot;,[&quot;Search&quot;,&quot;Reinforcement Learning&quot;],&quot;~:label&quot;,[[&quot;Plain&quot;,&quot;&quot;]],&quot;~:full_text&quot;,&quot;[[Reinforcement Learning]]&quot;,&quot;~:metadata&quot;,&quot;&quot;]]],536870960]],[&quot;^1=&quot;,[45,&quot;~:block/unordered&quot;,true,536870917]],[&quot;^1=&quot;,[45,&quot;^&gt;&quot;,&quot;~u60bab448-eaaf-4c42-8c1e-301359679240&quot;,536870917]],[&quot;^1=&quot;,[46,&quot;^1?&quot;,&quot;&quot;,536870917]],[&quot;^1=&quot;,[46,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[46,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[46,&quot;^X&quot;,&quot;&quot;,536870917]],[&quot;^1=&quot;,[46,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[46,&quot;^I&quot;,45,536870917]],[&quot;^1=&quot;,[46,&quot;^U&quot;,1,536870917]],[&quot;^1=&quot;,[46,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,29,&quot;^1F&quot;,30],536870917]],[&quot;^1=&quot;,[46,&quot;^13&quot;,24,536870917]],[&quot;^1=&quot;,[46,&quot;^10&quot;,24,536870917]],[&quot;^1=&quot;,[46,&quot;^W&quot;,[],536870917]],[&quot;^1=&quot;,[46,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[46,&quot;^&gt;&quot;,&quot;~u60bab448-59b8-47e5-bdc6-8639f7d2cba3&quot;,536870917]],[&quot;^1=&quot;,[47,&quot;^1?&quot;,&quot;An_agent_in_a__problem_setting_refers_to_the_learner_and_decision_maker-2e-_The_agent-27-s_sole_objective_is_to_maximize_its_total_reward_over_the_long_run-2e-&quot;,536870917]],[&quot;^1=&quot;,[47,&quot;^P&quot;,[],536870970]],[&quot;^1=&quot;,[47,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[47,&quot;^X&quot;,&quot;An agent in a [[Reinforcement Learning]] problem setting refers to the learner and decision maker. The agent&apos;s sole objective is to maximize its total reward over the long run.&quot;,536870917]],[&quot;^1=&quot;,[47,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[47,&quot;^I&quot;,103,536870970]],[&quot;^1=&quot;,[47,&quot;^U&quot;,1,536870970]],[&quot;^1=&quot;,[47,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,0,&quot;^1F&quot;,179],536870917]],[&quot;^1=&quot;,[47,&quot;^13&quot;,23,536870917]],[&quot;^1=&quot;,[47,&quot;^10&quot;,23,536870917]],[&quot;^1=&quot;,[47,&quot;^[&quot;,35,536870970]],[&quot;^1=&quot;,[47,&quot;^J&quot;,35,536870970]],[&quot;^1=&quot;,[47,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;An agent in a &quot;],[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[&quot;Search&quot;,&quot;Reinforcement Learning&quot;],&quot;^1H&quot;,[[&quot;Plain&quot;,&quot;&quot;]],&quot;^1I&quot;,&quot;[[Reinforcement Learning]]&quot;,&quot;^1J&quot;,&quot;&quot;]],[&quot;Plain&quot;,&quot; problem setting refers to the learner and decision maker. The agent&apos;s sole objective is to maximize its total reward over the long run.&quot;]],536870970]],[&quot;^1=&quot;,[47,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[47,&quot;^&gt;&quot;,&quot;~u60bab448-03f9-49ea-8845-2947f5d8eefb&quot;,536870917]],[&quot;^1=&quot;,[48,&quot;^1?&quot;,&quot;Returns&quot;,536870917]],[&quot;^1=&quot;,[48,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[48,&quot;^1@&quot;,[&quot;^1A&quot;,[[&quot;^&gt;&quot;,&quot;~u60bab448-6d79-48c8-96f0-1106df5dd560&quot;],[&quot;^&gt;&quot;,&quot;~u60bab448-e873-4ff8-9332-8302d266097d&quot;],[&quot;^&gt;&quot;,&quot;~u60bab19a-4583-4875-a49f-c572179ae136&quot;]]],536870917]],[&quot;^1=&quot;,[48,&quot;^X&quot;,&quot;Returns&quot;,536870917]],[&quot;^1=&quot;,[48,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[48,&quot;^I&quot;,47,536870917]],[&quot;^1=&quot;,[48,&quot;^U&quot;,1,536870917]],[&quot;^1=&quot;,[48,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,179,&quot;^1F&quot;,189],536870917]],[&quot;^1=&quot;,[48,&quot;^13&quot;,23,536870917]],[&quot;^1=&quot;,[48,&quot;^10&quot;,23,536870917]],[&quot;^1=&quot;,[48,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;Returns&quot;]],536870917]],[&quot;^1=&quot;,[48,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[48,&quot;^&gt;&quot;,&quot;~u60bab448-bf34-46bc-b1f2-7240897aa9cb&quot;,536870917]],[&quot;^1=&quot;,[49,&quot;^1?&quot;,&quot;The_goal_of_an_agent_is_to_maximize_the_total_cumulative_rewards_it_can_receive_in_the_long_run-2e-_The_long_term_reward-2c-_also_known_as_Return-2c-_is_the_total_sum_of_future_rewards-2c-&quot;,536870917]],[&quot;^1=&quot;,[49,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[49,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[49,&quot;^X&quot;,&quot;The goal of an agent is to maximize the total cumulative rewards it can receive in the long run. The long term reward, also known as **Return**, is the total sum of future rewards,\\nid:: 60bab19a-4583-4875-a49f-c572179ae136&quot;,536870917]],[&quot;^1=&quot;,[49,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[49,&quot;^I&quot;,48,536870917]],[&quot;^1=&quot;,[49,&quot;^U&quot;,2,536870917]],[&quot;^1=&quot;,[49,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,189,&quot;^1F&quot;,418],536870917]],[&quot;^1=&quot;,[49,&quot;^13&quot;,23,536870917]],[&quot;^1=&quot;,[49,&quot;^10&quot;,48,536870917]],[&quot;^1=&quot;,[49,&quot;^C&quot;,[&quot;^ &quot;,&quot;~:id&quot;,&quot;60bab19a-4583-4875-a49f-c572179ae136&quot;],536870917]],[&quot;^1=&quot;,[49,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;The goal of an agent is to maximize the total cumulative rewards it can receive in the long run. The long term reward, also known as &quot;],[&quot;Emphasis&quot;,[[&quot;Bold&quot;],[[&quot;Plain&quot;,&quot;Return&quot;]]]],[&quot;Plain&quot;,&quot;, is the total sum of future rewards,&quot;]],536870917]],[&quot;^1=&quot;,[49,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[49,&quot;^&gt;&quot;,&quot;~u60bab19a-4583-4875-a49f-c572179ae136&quot;,536870917]],[&quot;^1=&quot;,[50,&quot;^1?&quot;,&quot;&quot;,536870917]],[&quot;^1=&quot;,[50,&quot;^P&quot;,[[&quot;Displayed_Math&quot;,&quot;G_{t}=R_{t+1}+\\\\gamma R_{t+2}+\\\\cdots=\\\\sum_{k=0}^{\\\\infty} \\\\gamma^{k} R_{t+k+1}&quot;]],536870917]],[&quot;^1=&quot;,[50,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[50,&quot;^X&quot;,&quot;\\t  $$G_{t}=R_{t+1}+\\\\gamma R_{t+2}+\\\\cdots=\\\\sum_{k=0}^{\\\\infty} \\\\gamma^{k} R_{t+k+1}$$&quot;,536870917]],[&quot;^1=&quot;,[50,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[50,&quot;^I&quot;,49,536870917]],[&quot;^1=&quot;,[50,&quot;^U&quot;,2,536870917]],[&quot;^1=&quot;,[50,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,418,&quot;^1F&quot;,505],536870917]],[&quot;^1=&quot;,[50,&quot;^13&quot;,23,536870917]],[&quot;^1=&quot;,[50,&quot;^10&quot;,48,536870917]],[&quot;^1=&quot;,[50,&quot;^W&quot;,[],536870917]],[&quot;^1=&quot;,[50,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[50,&quot;^&gt;&quot;,&quot;~u60bab448-e873-4ff8-9332-8302d266097d&quot;,536870917]],[&quot;^1=&quot;,[51,&quot;^1?&quot;,&quot;where_-5c-gamma_is_a_parameter-2c-_0-5c-le-5c-gamma-5c-le1-2c-_called_discount_factor-2e-_The_discount_factor_penalizes_the_rewards_receive_in_the_future-2e-&quot;,536870917]],[&quot;^1=&quot;,[51,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[51,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[51,&quot;^X&quot;,&quot;where $\\\\gamma$ is a parameter, $0\\\\le\\\\gamma\\\\le1$, called *discount factor*. The discount factor penalizes the rewards receive in the future.&quot;,536870917]],[&quot;^1=&quot;,[51,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[51,&quot;^I&quot;,50,536870917]],[&quot;^1=&quot;,[51,&quot;^U&quot;,2,536870917]],[&quot;^1=&quot;,[51,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,505,&quot;^1F&quot;,648],536870917]],[&quot;^1=&quot;,[51,&quot;^13&quot;,23,536870917]],[&quot;^1=&quot;,[51,&quot;^10&quot;,48,536870917]],[&quot;^1=&quot;,[51,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;where &quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;\\\\gamma&quot;]],[&quot;Plain&quot;,&quot; is a parameter, &quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;0\\\\le\\\\gamma\\\\le1&quot;]],[&quot;Plain&quot;,&quot;, called &quot;],[&quot;Emphasis&quot;,[[&quot;Italic&quot;],[[&quot;Plain&quot;,&quot;discount factor&quot;]]]],[&quot;Plain&quot;,&quot;. The discount factor penalizes the rewards receive in the future.&quot;]],536870917]],[&quot;^1=&quot;,[51,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[51,&quot;^&gt;&quot;,&quot;~u60bab448-6d79-48c8-96f0-1106df5dd560&quot;,536870917]],[&quot;^1=&quot;,[52,&quot;^1?&quot;,&quot;Policy&quot;,536870917]],[&quot;^1=&quot;,[52,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[52,&quot;^1@&quot;,[&quot;^1A&quot;,[[&quot;^&gt;&quot;,&quot;~u60bab448-b089-4d39-b48e-8b51ee5f60ca&quot;],[&quot;^&gt;&quot;,&quot;~u60bab448-18f2-482d-bac5-129c80d85b50&quot;],[&quot;^&gt;&quot;,&quot;~u60bab1ac-1c32-4c47-ac87-3648dd4a905d&quot;]]],536870917]],[&quot;^1=&quot;,[52,&quot;^X&quot;,&quot;Policy&quot;,536870917]],[&quot;^1=&quot;,[52,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[52,&quot;^I&quot;,48,536870917]],[&quot;^1=&quot;,[52,&quot;^U&quot;,1,536870917]],[&quot;^1=&quot;,[52,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,648,&quot;^1F&quot;,657],536870917]],[&quot;^1=&quot;,[52,&quot;^13&quot;,23,536870917]],[&quot;^1=&quot;,[52,&quot;^10&quot;,23,536870917]],[&quot;^1=&quot;,[52,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;Policy&quot;]],536870917]],[&quot;^1=&quot;,[52,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[52,&quot;^&gt;&quot;,&quot;~u60bab448-85a4-4d2d-9ecb-346e03e21ede&quot;,536870917]],[&quot;^1=&quot;,[53,&quot;^1?&quot;,&quot;A_policy_defines_the_learning_agent-27-s_way_of_behaving_at_a_given_time-2e-_In_other_way-2c-_the_behavior_of_an_agent_is_controlled_by_its_policy_-5c-pi-2e-_It_will_tell_us_which_action_the_agent_will_take_given_the_current_state_of_the_-2e-_It_can_be_viewed_as_a_map_from_state_s_to_action_a_when_agent_is_in_that_state_s-2e-&quot;,536870917]],[&quot;^1=&quot;,[53,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[53,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[53,&quot;^X&quot;,&quot;A *policy* defines the learning agent&apos;s way of behaving at a given time. In other way, the behavior of an agent is controlled by its policy $\\\\pi$. It will tell us which action the agent will take given the current state of the [[Environment]]. It can be viewed as a map from state $s$ to action $a$ when agent is in that state $s$.\\nid:: 60bab1ac-1c32-4c47-ac87-3648dd4a905d&quot;,536870917]],[&quot;^1=&quot;,[53,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[53,&quot;^I&quot;,52,536870917]],[&quot;^1=&quot;,[53,&quot;^U&quot;,2,536870917]],[&quot;^1=&quot;,[53,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,657,&quot;^1F&quot;,1037],536870917]],[&quot;^1=&quot;,[53,&quot;^13&quot;,23,536870917]],[&quot;^1=&quot;,[53,&quot;^10&quot;,52,536870917]],[&quot;^1=&quot;,[53,&quot;^[&quot;,34,536870917]],[&quot;^1=&quot;,[53,&quot;^C&quot;,[&quot;^ &quot;,&quot;^1L&quot;,&quot;60bab1ac-1c32-4c47-ac87-3648dd4a905d&quot;],536870917]],[&quot;^1=&quot;,[53,&quot;^J&quot;,34,536870917]],[&quot;^1=&quot;,[53,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;A &quot;],[&quot;Emphasis&quot;,[[&quot;Italic&quot;],[[&quot;Plain&quot;,&quot;policy&quot;]]]],[&quot;Plain&quot;,&quot; defines the learning agent&apos;s way of behaving at a given time. In other way, the behavior of an agent is controlled by its policy &quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;\\\\pi&quot;]],[&quot;Plain&quot;,&quot;. It will tell us which action the agent will take given the current state of the &quot;],[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[&quot;Search&quot;,&quot;Environment&quot;],&quot;^1H&quot;,[[&quot;Plain&quot;,&quot;&quot;]],&quot;^1I&quot;,&quot;[[Environment]]&quot;,&quot;^1J&quot;,&quot;&quot;]],[&quot;Plain&quot;,&quot;. It can be viewed as a map from state &quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;s&quot;]],[&quot;Plain&quot;,&quot; to action &quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;a&quot;]],[&quot;Plain&quot;,&quot; when agent is in that state &quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;s&quot;]],[&quot;Plain&quot;,&quot;.&quot;]],536870917]],[&quot;^1=&quot;,[53,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[53,&quot;^&gt;&quot;,&quot;~u60bab1ac-1c32-4c47-ac87-3648dd4a905d&quot;,536870917]],[&quot;^1=&quot;,[54,&quot;^1?&quot;,&quot;Deterministic_Policy&quot;,536870917]],[&quot;^1=&quot;,[54,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[54,&quot;^1@&quot;,[&quot;^1A&quot;,[[&quot;^&gt;&quot;,&quot;~u60bab448-2df7-4d34-86be-3e157f3e7454&quot;]]],536870917]],[&quot;^1=&quot;,[54,&quot;^X&quot;,&quot;Deterministic Policy&quot;,536870917]],[&quot;^1=&quot;,[54,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[54,&quot;^I&quot;,53,536870917]],[&quot;^1=&quot;,[54,&quot;^U&quot;,2,536870917]],[&quot;^1=&quot;,[54,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,1037,&quot;^1F&quot;,1061],536870917]],[&quot;^1=&quot;,[54,&quot;^13&quot;,23,536870917]],[&quot;^1=&quot;,[54,&quot;^10&quot;,52,536870917]],[&quot;^1=&quot;,[54,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;Deterministic Policy&quot;]],536870917]],[&quot;^1=&quot;,[54,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[54,&quot;^&gt;&quot;,&quot;~u60bab448-18f2-482d-bac5-129c80d85b50&quot;,536870917]],[&quot;^1=&quot;,[55,&quot;^1?&quot;,&quot;-5c-pi(s)_-3d-_a&quot;,536870917]],[&quot;^1=&quot;,[55,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[55,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[55,&quot;^X&quot;,&quot;$\\\\pi(s) = a$&quot;,536870917]],[&quot;^1=&quot;,[55,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[55,&quot;^I&quot;,54,536870917]],[&quot;^1=&quot;,[55,&quot;^U&quot;,3,536870917]],[&quot;^1=&quot;,[55,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,1061,&quot;^1F&quot;,1078],536870917]],[&quot;^1=&quot;,[55,&quot;^13&quot;,23,536870917]],[&quot;^1=&quot;,[55,&quot;^10&quot;,54,536870917]],[&quot;^1=&quot;,[55,&quot;^W&quot;,[[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;\\\\pi(s) = a&quot;]]],536870917]],[&quot;^1=&quot;,[55,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[55,&quot;^&gt;&quot;,&quot;~u60bab448-2df7-4d34-86be-3e157f3e7454&quot;,536870917]],[&quot;^1=&quot;,[56,&quot;^1?&quot;,&quot;Stochastic_Policy&quot;,536870917]],[&quot;^1=&quot;,[56,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[56,&quot;^1@&quot;,[&quot;^1A&quot;,[[&quot;^&gt;&quot;,&quot;~u60bab448-e8af-4785-8148-c61ff2dfb80b&quot;]]],536870917]],[&quot;^1=&quot;,[56,&quot;^X&quot;,&quot;Stochastic Policy&quot;,536870917]],[&quot;^1=&quot;,[56,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[56,&quot;^I&quot;,54,536870917]],[&quot;^1=&quot;,[56,&quot;^U&quot;,2,536870917]],[&quot;^1=&quot;,[56,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,1078,&quot;^1F&quot;,1099],536870917]],[&quot;^1=&quot;,[56,&quot;^13&quot;,23,536870917]],[&quot;^1=&quot;,[56,&quot;^10&quot;,52,536870917]],[&quot;^1=&quot;,[56,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;Stochastic Policy&quot;]],536870917]],[&quot;^1=&quot;,[56,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[56,&quot;^&gt;&quot;,&quot;~u60bab448-b089-4d39-b48e-8b51ee5f60ca&quot;,536870917]],[&quot;^1=&quot;,[57,&quot;^1?&quot;,&quot;-5c-pi(a-7c-s)_-3d-_-5c-mathbb-7b-P-7d-_-7b--5c-pi-7d--5b-A-3d-a-7c-S-3d-s-5d-&quot;,536870917]],[&quot;^1=&quot;,[57,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[57,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[57,&quot;^X&quot;,&quot;$\\\\pi(a|s) = \\\\mathbb{P}_{\\\\pi}[A=a|S=s]$&quot;,536870917]],[&quot;^1=&quot;,[57,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[57,&quot;^I&quot;,56,536870917]],[&quot;^1=&quot;,[57,&quot;^U&quot;,3,536870917]],[&quot;^1=&quot;,[57,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,1099,&quot;^1F&quot;,1142],536870917]],[&quot;^1=&quot;,[57,&quot;^13&quot;,23,536870917]],[&quot;^1=&quot;,[57,&quot;^10&quot;,56,536870917]],[&quot;^1=&quot;,[57,&quot;^W&quot;,[[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;\\\\pi(a|s) = \\\\mathbb{P}_{\\\\pi}[A=a|S=s]&quot;]]],536870917]],[&quot;^1=&quot;,[57,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[57,&quot;^&gt;&quot;,&quot;~u60bab448-e8af-4785-8148-c61ff2dfb80b&quot;,536870917]],[&quot;^1=&quot;,[58,&quot;^1?&quot;,&quot;Value_Function&quot;,536870917]],[&quot;^1=&quot;,[58,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[58,&quot;^1@&quot;,[&quot;^1A&quot;,[[&quot;^&gt;&quot;,&quot;~u60bab448-a7a8-440e-a2c4-245a5dab8965&quot;],[&quot;^&gt;&quot;,&quot;~u60bab448-03c3-4aec-9350-1899812e4964&quot;],[&quot;^&gt;&quot;,&quot;~u60bab448-a1a6-4ec9-a017-1c566d2354f7&quot;],[&quot;^&gt;&quot;,&quot;~u60bab448-4f26-4b9c-9808-a58e1b02ccae&quot;],[&quot;^&gt;&quot;,&quot;~u60bab448-e565-46fa-a827-c542948e3598&quot;],[&quot;^&gt;&quot;,&quot;~u60bab448-a803-4ebd-bffb-f32fbc4821c0&quot;],[&quot;^&gt;&quot;,&quot;~u60bab448-e24f-41fb-9607-6ee20c305d2b&quot;],[&quot;^&gt;&quot;,&quot;~u60bab1cc-0172-486f-9cad-f43867642b45&quot;]]],536870917]],[&quot;^1=&quot;,[58,&quot;^X&quot;,&quot;Value Function&quot;,536870917]],[&quot;^1=&quot;,[58,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[58,&quot;^I&quot;,52,536870917]],[&quot;^1=&quot;,[58,&quot;^U&quot;,1,536870917]],[&quot;^1=&quot;,[58,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,1142,&quot;^1F&quot;,1159],536870917]],[&quot;^1=&quot;,[58,&quot;^13&quot;,23,536870917]],[&quot;^1=&quot;,[58,&quot;^10&quot;,23,536870917]],[&quot;^1=&quot;,[58,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;Value Function&quot;]],536870917]],[&quot;^1=&quot;,[58,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[58,&quot;^&gt;&quot;,&quot;~u60bab448-5fa7-47c7-bb7d-daa4498c3372&quot;,536870917]],[&quot;^1=&quot;,[59,&quot;^1?&quot;,&quot;A_value_function_indicates_what_is_good_for_the_agent_in_the_long_run-2c-_whereas_reward_signal_tells_the_agent_which_action_is_good_in_the_short_run-2e-_It_measures_how_good_a_state_s_is_following_a_given_policy_-5c-pi-2e-&quot;,536870917]],[&quot;^1=&quot;,[59,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[59,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[59,&quot;^X&quot;,&quot;A value function indicates what is good for the agent in the long run, whereas reward signal tells the agent which action is good in the short run. It measures how good a state $s$ is following a given policy $\\\\pi$.\\nid:: 60bab1cc-0172-486f-9cad-f43867642b45&quot;,536870917]],[&quot;^1=&quot;,[59,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[59,&quot;^I&quot;,58,536870917]],[&quot;^1=&quot;,[59,&quot;^U&quot;,2,536870917]],[&quot;^1=&quot;,[59,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,1159,&quot;^1F&quot;,1423],536870917]],[&quot;^1=&quot;,[59,&quot;^13&quot;,23,536870917]],[&quot;^1=&quot;,[59,&quot;^10&quot;,58,536870917]],[&quot;^1=&quot;,[59,&quot;^C&quot;,[&quot;^ &quot;,&quot;^1L&quot;,&quot;60bab1cc-0172-486f-9cad-f43867642b45&quot;],536870917]],[&quot;^1=&quot;,[59,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;A value function indicates what is good for the agent in the long run, whereas reward signal tells the agent which action is good in the short run. It measures how good a state &quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;s&quot;]],[&quot;Plain&quot;,&quot; is following a given policy &quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;\\\\pi&quot;]],[&quot;Plain&quot;,&quot;.&quot;]],536870917]],[&quot;^1=&quot;,[59,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[59,&quot;^&gt;&quot;,&quot;~u60bab1cc-0172-486f-9cad-f43867642b45&quot;,536870917]],[&quot;^1=&quot;,[60,&quot;^1?&quot;,&quot;The_state_value_function_for_policy_-5c-pi__of_a_state_s_at_time_t_is&quot;,536870917]],[&quot;^1=&quot;,[60,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[60,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[60,&quot;^X&quot;,&quot;The **state-value** function for policy $\\\\pi$  of a state $s$ at time $t$ is&quot;,536870917]],[&quot;^1=&quot;,[60,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[60,&quot;^I&quot;,59,536870917]],[&quot;^1=&quot;,[60,&quot;^U&quot;,2,536870917]],[&quot;^1=&quot;,[60,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,1423,&quot;^1F&quot;,1503],536870917]],[&quot;^1=&quot;,[60,&quot;^13&quot;,23,536870917]],[&quot;^1=&quot;,[60,&quot;^10&quot;,58,536870917]],[&quot;^1=&quot;,[60,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;The &quot;],[&quot;Emphasis&quot;,[[&quot;Bold&quot;],[[&quot;Plain&quot;,&quot;state-value&quot;]]]],[&quot;Plain&quot;,&quot; function for policy &quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;\\\\pi&quot;]],[&quot;Plain&quot;,&quot;  of a state &quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;s&quot;]],[&quot;Plain&quot;,&quot; at time &quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;t&quot;]],[&quot;Plain&quot;,&quot; is&quot;]],536870917]],[&quot;^1=&quot;,[60,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[60,&quot;^&gt;&quot;,&quot;~u60bab448-e24f-41fb-9607-6ee20c305d2b&quot;,536870917]],[&quot;^1=&quot;,[61,&quot;^1?&quot;,&quot;&quot;,536870917]],[&quot;^1=&quot;,[61,&quot;^P&quot;,[[&quot;Displayed_Math&quot;,&quot;V_{\\\\pi}(s) = \\\\mathbb{E}[G_t|S_t = s] = \\\\mathbb{E}\\\\left[\\\\sum_{k=0}^{\\\\infty}\\\\gamma^kR_{t+k+1}|S_t=s\\\\right], \\\\text{  for all  } s\\\\in S&quot;]],536870917]],[&quot;^1=&quot;,[61,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[61,&quot;^X&quot;,&quot;\\t  $$V_{\\\\pi}(s) = \\\\mathbb{E}[G_t|S_t = s] = \\\\mathbb{E}\\\\left[\\\\sum_{k=0}^{\\\\infty}\\\\gamma^kR_{t+k+1}|S_t=s\\\\right], \\\\text{  for all  } s\\\\in S$$&quot;,536870917]],[&quot;^1=&quot;,[61,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[61,&quot;^I&quot;,60,536870917]],[&quot;^1=&quot;,[61,&quot;^U&quot;,2,536870917]],[&quot;^1=&quot;,[61,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,1503,&quot;^1F&quot;,1645],536870917]],[&quot;^1=&quot;,[61,&quot;^13&quot;,23,536870917]],[&quot;^1=&quot;,[61,&quot;^10&quot;,58,536870917]],[&quot;^1=&quot;,[61,&quot;^W&quot;,[],536870917]],[&quot;^1=&quot;,[61,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[61,&quot;^&gt;&quot;,&quot;~u60bab448-a803-4ebd-bffb-f32fbc4821c0&quot;,536870917]],[&quot;^1=&quot;,[62,&quot;^1?&quot;,&quot;The_action_value_function_of_taking_action_a_in_state_s_under_a_policy_-5c-pi_is&quot;,536870917]],[&quot;^1=&quot;,[62,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[62,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[62,&quot;^X&quot;,&quot;The **action-value** function of taking action $a$ in state $s$ under a policy $\\\\pi$ is&quot;,536870917]],[&quot;^1=&quot;,[62,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[62,&quot;^I&quot;,61,536870917]],[&quot;^1=&quot;,[62,&quot;^U&quot;,2,536870917]],[&quot;^1=&quot;,[62,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,1645,&quot;^1F&quot;,1736],536870917]],[&quot;^1=&quot;,[62,&quot;^13&quot;,23,536870917]],[&quot;^1=&quot;,[62,&quot;^10&quot;,58,536870917]],[&quot;^1=&quot;,[62,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;The &quot;],[&quot;Emphasis&quot;,[[&quot;Bold&quot;],[[&quot;Plain&quot;,&quot;action-value&quot;]]]],[&quot;Plain&quot;,&quot; function of taking action &quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;a&quot;]],[&quot;Plain&quot;,&quot; in state &quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;s&quot;]],[&quot;Plain&quot;,&quot; under a policy &quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;\\\\pi&quot;]],[&quot;Plain&quot;,&quot; is&quot;]],536870917]],[&quot;^1=&quot;,[62,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[62,&quot;^&gt;&quot;,&quot;~u60bab448-e565-46fa-a827-c542948e3598&quot;,536870917]],[&quot;^1=&quot;,[63,&quot;^1?&quot;,&quot;&quot;,536870917]],[&quot;^1=&quot;,[63,&quot;^P&quot;,[[&quot;Displayed_Math&quot;,&quot;Q_{\\\\pi}(s, a)=\\\\mathbb{E}_{\\\\pi}\\\\left[G_{t} \\\\mid S_{t}=s, A_{t}=a\\\\right]=\\\\mathbb{E}\\\\left[\\\\sum_{k=0}^{\\\\infty}\\\\gamma^kR_{t+k+1}|S_t=s, A_t = a\\\\right]&quot;]],536870917]],[&quot;^1=&quot;,[63,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[63,&quot;^X&quot;,&quot;\\t  $$Q_{\\\\pi}(s, a)=\\\\mathbb{E}_{\\\\pi}\\\\left[G_{t} \\\\mid S_{t}=s, A_{t}=a\\\\right]=\\\\mathbb{E}\\\\left[\\\\sum_{k=0}^{\\\\infty}\\\\gamma^kR_{t+k+1}|S_t=s, A_t = a\\\\right]$$&quot;,536870917]],[&quot;^1=&quot;,[63,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[63,&quot;^I&quot;,62,536870917]],[&quot;^1=&quot;,[63,&quot;^U&quot;,2,536870917]],[&quot;^1=&quot;,[63,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,1736,&quot;^1F&quot;,1892],536870917]],[&quot;^1=&quot;,[63,&quot;^13&quot;,23,536870917]],[&quot;^1=&quot;,[63,&quot;^10&quot;,58,536870917]],[&quot;^1=&quot;,[63,&quot;^W&quot;,[],536870917]],[&quot;^1=&quot;,[63,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[63,&quot;^&gt;&quot;,&quot;~u60bab448-4f26-4b9c-9808-a58e1b02ccae&quot;,536870917]],[&quot;^1=&quot;,[64,&quot;^1?&quot;,&quot;Since_the_agent_is_following_the_same_policy_-7c-pi-2c-_we_can_use_the_expectation_over_all_possible_actions_value_function_to_recover_the_state_value_function&quot;,536870917]],[&quot;^1=&quot;,[64,&quot;^P&quot;,[[&quot;Displayed_Math&quot;,&quot; V_{\\\\pi}(s) = \\\\sum_{a \\\\in \\\\mathcal{A}} Q_{\\\\pi}(s, a)\\\\pi(s|a)&quot;]],536870917]],[&quot;^1=&quot;,[64,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[64,&quot;^X&quot;,&quot;Since the agent is following the same policy $|pi$, we can use the expectation over all possible actions-value function to recover the state-value function\\n$$ V_{\\\\pi}(s) = \\\\sum_{a \\\\in \\\\mathcal{A}} Q_{\\\\pi}(s, a)\\\\pi(s|a)$$&quot;,536870917]],[&quot;^1=&quot;,[64,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[64,&quot;^I&quot;,63,536870917]],[&quot;^1=&quot;,[64,&quot;^U&quot;,2,536870917]],[&quot;^1=&quot;,[64,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,1892,&quot;^1F&quot;,2119],536870917]],[&quot;^1=&quot;,[64,&quot;^13&quot;,23,536870917]],[&quot;^1=&quot;,[64,&quot;^10&quot;,58,536870917]],[&quot;^1=&quot;,[64,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;Since the agent is following the same policy &quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;|pi&quot;]],[&quot;Plain&quot;,&quot;, we can use the expectation over all possible actions-value function to recover the state-value function&quot;]],536870917]],[&quot;^1=&quot;,[64,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[64,&quot;^&gt;&quot;,&quot;~u60bab448-a1a6-4ec9-a017-1c566d2354f7&quot;,536870917]],[&quot;^1=&quot;,[65,&quot;^1?&quot;,&quot;Link-3a-&quot;,536870917]],[&quot;^1=&quot;,[65,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[65,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[65,&quot;^X&quot;,&quot;Link:&quot;,536870917]],[&quot;^1=&quot;,[65,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[65,&quot;^I&quot;,64,536870917]],[&quot;^1=&quot;,[65,&quot;^U&quot;,2,536870917]],[&quot;^1=&quot;,[65,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,2119,&quot;^1F&quot;,2128],536870917]],[&quot;^1=&quot;,[65,&quot;^13&quot;,23,536870917]],[&quot;^1=&quot;,[65,&quot;^10&quot;,58,536870917]],[&quot;^1=&quot;,[65,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;Link:&quot;]],536870917]],[&quot;^1=&quot;,[65,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[65,&quot;^&gt;&quot;,&quot;~u60bab448-03c3-4aec-9350-1899812e4964&quot;,536870917]],[&quot;^1=&quot;,[66,&quot;^1?&quot;,&quot;&quot;,536870917]],[&quot;^1=&quot;,[66,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[66,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[66,&quot;^X&quot;,&quot;[[Reinforcement Learning]]&quot;,536870917]],[&quot;^1=&quot;,[66,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[66,&quot;^I&quot;,65,536870917]],[&quot;^1=&quot;,[66,&quot;^U&quot;,2,536870917]],[&quot;^1=&quot;,[66,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,2128,&quot;^1F&quot;,2157],536870917]],[&quot;^1=&quot;,[66,&quot;^13&quot;,23,536870917]],[&quot;^1=&quot;,[66,&quot;^10&quot;,58,536870917]],[&quot;^1=&quot;,[66,&quot;^[&quot;,35,536870917]],[&quot;^1=&quot;,[66,&quot;^J&quot;,35,536870917]],[&quot;^1=&quot;,[66,&quot;^W&quot;,[[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[&quot;Search&quot;,&quot;Reinforcement Learning&quot;],&quot;^1H&quot;,[[&quot;Plain&quot;,&quot;&quot;]],&quot;^1I&quot;,&quot;[[Reinforcement Learning]]&quot;,&quot;^1J&quot;,&quot;&quot;]]],536870917]],[&quot;^1=&quot;,[66,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[66,&quot;^&gt;&quot;,&quot;~u60bab448-a7a8-440e-a2c4-245a5dab8965&quot;,536870917]],[&quot;^1=&quot;,[67,&quot;^1?&quot;,&quot;An_environment_is_the_thing_an_agent_interacts_with-2c-_comprising_everything_outside_the_agent-2e-_It_provides_its_states_and_delivers_reward_to_any_agent_that_is_acting_in_it_with_rewards_following_its_model-2e-&quot;,536870917]],[&quot;^1=&quot;,[67,&quot;^P&quot;,[],536870975]],[&quot;^1=&quot;,[67,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[67,&quot;^X&quot;,&quot;An environment is the thing an agent interacts with, comprising everything outside the agent. It provides its states and delivers reward to any agent that is acting in it with rewards following its model.&quot;,536870917]],[&quot;^1=&quot;,[67,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[67,&quot;^I&quot;,104,536870975]],[&quot;^1=&quot;,[67,&quot;^U&quot;,1,536870975]],[&quot;^1=&quot;,[67,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,0,&quot;^1F&quot;,207],536870917]],[&quot;^1=&quot;,[67,&quot;^13&quot;,34,536870917]],[&quot;^1=&quot;,[67,&quot;^10&quot;,34,536870917]],[&quot;^1=&quot;,[67,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;An environment is the thing an agent interacts with, comprising everything outside the agent. It provides its states and delivers reward to any agent that is acting in it with rewards following its model.&quot;]],536870975]],[&quot;^1=&quot;,[67,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[67,&quot;^&gt;&quot;,&quot;~u60bab449-26ad-492a-95fd-592e2a3da9a0&quot;,536870917]],[&quot;^1=&quot;,[68,&quot;^1?&quot;,&quot;Reward&quot;,536870917]],[&quot;^1=&quot;,[68,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[68,&quot;^1@&quot;,[&quot;^1A&quot;,[[&quot;^&gt;&quot;,&quot;~u60bab0a3-2a58-4de2-9689-a1ce280de44a&quot;],[&quot;^&gt;&quot;,&quot;~u60bab0a9-72f9-43d6-9160-34b517c50d9b&quot;]]],536870917]],[&quot;^1=&quot;,[68,&quot;^X&quot;,&quot;Reward&quot;,536870917]],[&quot;^1=&quot;,[68,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[68,&quot;^I&quot;,67,536870917]],[&quot;^1=&quot;,[68,&quot;^U&quot;,1,536870917]],[&quot;^1=&quot;,[68,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,207,&quot;^1F&quot;,216],536870917]],[&quot;^1=&quot;,[68,&quot;^13&quot;,34,536870917]],[&quot;^1=&quot;,[68,&quot;^10&quot;,34,536870917]],[&quot;^1=&quot;,[68,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;Reward&quot;]],536870917]],[&quot;^1=&quot;,[68,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[68,&quot;^&gt;&quot;,&quot;~u60bab449-8223-4b51-9da2-f30e00a9b356&quot;,536870917]],[&quot;^1=&quot;,[69,&quot;^1?&quot;,&quot;Reward_is_the_feedback_an_environment_provides_to_the__when_it_receives_a_valid_action-2e-_In_general-2c-_reward_signals_may_be_stochastic_functions_of_the_state_of_the_environment_and_the_actions_of_the_-2e-_This_reward_we_may_or_may_not_know-2e-_In_practice-2c-_we_will_try_to_maximize_an_agent-27-s_reward-2e-&quot;,536870917]],[&quot;^1=&quot;,[69,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[69,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[69,&quot;^X&quot;,&quot;Reward is the feedback an environment provides to the [[Agent]] when it receives a valid action. In general, reward signals may be stochastic functions of the state of the environment and the actions of the [[Agent]]. This reward we may or may not know. In practice, we will try to maximize an agent&apos;s reward.\\nid:: 60bab0a9-72f9-43d6-9160-34b517c50d9b&quot;,536870917]],[&quot;^1=&quot;,[69,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[69,&quot;^I&quot;,68,536870917]],[&quot;^1=&quot;,[69,&quot;^U&quot;,2,536870917]],[&quot;^1=&quot;,[69,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,216,&quot;^1F&quot;,574],536870917]],[&quot;^1=&quot;,[69,&quot;^13&quot;,34,536870917]],[&quot;^1=&quot;,[69,&quot;^10&quot;,68,536870917]],[&quot;^1=&quot;,[69,&quot;^[&quot;,23,536870917]],[&quot;^1=&quot;,[69,&quot;^C&quot;,[&quot;^ &quot;,&quot;^1L&quot;,&quot;60bab0a9-72f9-43d6-9160-34b517c50d9b&quot;],536870917]],[&quot;^1=&quot;,[69,&quot;^J&quot;,23,536870917]],[&quot;^1=&quot;,[69,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;Reward is the feedback an environment provides to the &quot;],[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[&quot;Search&quot;,&quot;Agent&quot;],&quot;^1H&quot;,[[&quot;Plain&quot;,&quot;&quot;]],&quot;^1I&quot;,&quot;[[Agent]]&quot;,&quot;^1J&quot;,&quot;&quot;]],[&quot;Plain&quot;,&quot; when it receives a valid action. In general, reward signals may be stochastic functions of the state of the environment and the actions of the &quot;],[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[&quot;Search&quot;,&quot;Agent&quot;],&quot;^1H&quot;,[[&quot;Plain&quot;,&quot;&quot;]],&quot;^1I&quot;,&quot;[[Agent]]&quot;,&quot;^1J&quot;,&quot;&quot;]],[&quot;Plain&quot;,&quot;. This reward we may or may not know. In practice, we will try to maximize an agent&apos;s reward.&quot;]],536870917]],[&quot;^1=&quot;,[69,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[69,&quot;^&gt;&quot;,&quot;~u60bab0a9-72f9-43d6-9160-34b517c50d9b&quot;,536870917]],[&quot;^1=&quot;,[70,&quot;^1?&quot;,&quot;The_reward_function_R_predicts_the_next_reward_triggered_by_an_action_a-3a-&quot;,536870917]],[&quot;^1=&quot;,[70,&quot;^P&quot;,[[&quot;Displayed_Math&quot;,&quot;R(s, a)=\\\\mathbb{E}\\\\left[R_{t+1} \\\\mid S_{t}=s, A_{t}=a\\\\right]=\\\\sum_{r \\\\in \\\\mathcal{R}} r \\\\sum_{s^{\\\\prime} \\\\in S} P\\\\left(s^{\\\\prime}, r \\\\mid s, a\\\\right)&quot;]],536870917]],[&quot;^1=&quot;,[70,&quot;^1@&quot;,[&quot;^1A&quot;,[[&quot;^&gt;&quot;,&quot;~u60bab449-3555-4cab-bbef-ff0f2d81ae6b&quot;],[&quot;^&gt;&quot;,&quot;~u60bab449-6625-4860-8653-97cff5168bb3&quot;]]],536870917]],[&quot;^1=&quot;,[70,&quot;^X&quot;,&quot;The reward function $R$ predicts the next reward triggered by an action $a$:\\nid:: 60bab0a3-2a58-4de2-9689-a1ce280de44a\\n$$R(s, a)=\\\\mathbb{E}\\\\left[R_{t+1} \\\\mid S_{t}=s, A_{t}=a\\\\right]=\\\\sum_{r \\\\in \\\\mathcal{R}} r \\\\sum_{s^{\\\\prime} \\\\in S} P\\\\left(s^{\\\\prime}, r \\\\mid s, a\\\\right)$$&quot;,536870917]],[&quot;^1=&quot;,[70,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[70,&quot;^I&quot;,69,536870917]],[&quot;^1=&quot;,[70,&quot;^U&quot;,2,536870917]],[&quot;^1=&quot;,[70,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,574,&quot;^1F&quot;,856],536870917]],[&quot;^1=&quot;,[70,&quot;^13&quot;,34,536870917]],[&quot;^1=&quot;,[70,&quot;^10&quot;,68,536870917]],[&quot;^1=&quot;,[70,&quot;^C&quot;,[&quot;^ &quot;,&quot;^1L&quot;,&quot;60bab0a3-2a58-4de2-9689-a1ce280de44a&quot;],536870917]],[&quot;^1=&quot;,[70,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;The reward function &quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;R&quot;]],[&quot;Plain&quot;,&quot; predicts the next reward triggered by an action &quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;a&quot;]],[&quot;Plain&quot;,&quot;:&quot;]],536870917]],[&quot;^1=&quot;,[70,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[70,&quot;^&gt;&quot;,&quot;~u60bab0a3-2a58-4de2-9689-a1ce280de44a&quot;,536870917]],[&quot;^1=&quot;,[71,&quot;^1?&quot;,&quot;Known_reward&quot;,536870917]],[&quot;^1=&quot;,[71,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[71,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[71,&quot;^X&quot;,&quot;Known reward&quot;,536870917]],[&quot;^1=&quot;,[71,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[71,&quot;^I&quot;,70,536870917]],[&quot;^1=&quot;,[71,&quot;^U&quot;,3,536870917]],[&quot;^1=&quot;,[71,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,856,&quot;^1F&quot;,873],536870917]],[&quot;^1=&quot;,[71,&quot;^13&quot;,34,536870917]],[&quot;^1=&quot;,[71,&quot;^10&quot;,70,536870917]],[&quot;^1=&quot;,[71,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;Known reward&quot;]],536870917]],[&quot;^1=&quot;,[71,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[71,&quot;^&gt;&quot;,&quot;~u60bab449-6625-4860-8653-97cff5168bb3&quot;,536870917]],[&quot;^1=&quot;,[72,&quot;^1?&quot;,&quot;Unknown_reward&quot;,536870917]],[&quot;^1=&quot;,[72,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[72,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[72,&quot;^X&quot;,&quot;Unknown reward&quot;,536870917]],[&quot;^1=&quot;,[72,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[72,&quot;^I&quot;,71,536870917]],[&quot;^1=&quot;,[72,&quot;^U&quot;,3,536870917]],[&quot;^1=&quot;,[72,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,873,&quot;^1F&quot;,892],536870917]],[&quot;^1=&quot;,[72,&quot;^13&quot;,34,536870917]],[&quot;^1=&quot;,[72,&quot;^10&quot;,70,536870917]],[&quot;^1=&quot;,[72,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;Unknown reward&quot;]],536870917]],[&quot;^1=&quot;,[72,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[72,&quot;^&gt;&quot;,&quot;~u60bab449-3555-4cab-bbef-ff0f2d81ae6b&quot;,536870917]],[&quot;^1=&quot;,[73,&quot;^1?&quot;,&quot;Model&quot;,536870917]],[&quot;^1=&quot;,[73,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[73,&quot;^1@&quot;,[&quot;^1A&quot;,[[&quot;^&gt;&quot;,&quot;~u60bab449-e0d6-4dfc-ba5f-b856e2a7b590&quot;],[&quot;^&gt;&quot;,&quot;~u60bab15b-57ca-48e8-863b-fd4c5745a2e3&quot;]]],536870917]],[&quot;^1=&quot;,[73,&quot;^X&quot;,&quot;Model&quot;,536870917]],[&quot;^1=&quot;,[73,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[73,&quot;^I&quot;,68,536870917]],[&quot;^1=&quot;,[73,&quot;^U&quot;,1,536870917]],[&quot;^1=&quot;,[73,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,892,&quot;^1F&quot;,900],536870917]],[&quot;^1=&quot;,[73,&quot;^13&quot;,34,536870917]],[&quot;^1=&quot;,[73,&quot;^10&quot;,34,536870917]],[&quot;^1=&quot;,[73,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;Model&quot;]],536870917]],[&quot;^1=&quot;,[73,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[73,&quot;^&gt;&quot;,&quot;~u60bab449-20d9-45ba-9720-3a93ffbba19c&quot;,536870917]],[&quot;^1=&quot;,[74,&quot;^1?&quot;,&quot;Model_is_a_descriptor_of_the_environment-2c-_it_defines_how_the_environment_performs_internally_and_externally-2e-_With_the_model-2c-_we_can_learn_or_infer_how_the_environment_would_interact_with_and_provide_feedback_to_the_agent-2e-_The_model_has_two_major_parts-2c-_transition_probability_function_P_and_reward_function_R-2e-&quot;,536870917]],[&quot;^1=&quot;,[74,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[74,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[74,&quot;^X&quot;,&quot;Model is a descriptor of the environment, it defines how the environment performs internally and externally. With the model, we can learn or infer how the environment would interact with and provide feedback to the agent. The model has two major parts, transition probability function $P$ and reward function $R$. \\nid:: 60bab15b-57ca-48e8-863b-fd4c5745a2e3&quot;,536870917]],[&quot;^1=&quot;,[74,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[74,&quot;^I&quot;,73,536870917]],[&quot;^1=&quot;,[74,&quot;^U&quot;,2,536870917]],[&quot;^1=&quot;,[74,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,900,&quot;^1F&quot;,1263],536870917]],[&quot;^1=&quot;,[74,&quot;^13&quot;,34,536870917]],[&quot;^1=&quot;,[74,&quot;^10&quot;,73,536870917]],[&quot;^1=&quot;,[74,&quot;^C&quot;,[&quot;^ &quot;,&quot;^1L&quot;,&quot;60bab15b-57ca-48e8-863b-fd4c5745a2e3&quot;],536870917]],[&quot;^1=&quot;,[74,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;Model is a descriptor of the environment, it defines how the environment performs internally and externally. With the model, we can learn or infer how the environment would interact with and provide feedback to the agent. The model has two major parts, transition probability function &quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;P&quot;]],[&quot;Plain&quot;,&quot; and reward function &quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;R&quot;]],[&quot;Plain&quot;,&quot;.&quot;]],536870917]],[&quot;^1=&quot;,[74,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[74,&quot;^&gt;&quot;,&quot;~u60bab15b-57ca-48e8-863b-fd4c5745a2e3&quot;,536870917]],[&quot;^1=&quot;,[75,&quot;^1?&quot;,&quot;Transition-3a-&quot;,536870917]],[&quot;^1=&quot;,[75,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[75,&quot;^1@&quot;,[&quot;^1A&quot;,[[&quot;^&gt;&quot;,&quot;~u60bab449-279c-41c1-87a4-bbf55a29a4af&quot;],[&quot;^&gt;&quot;,&quot;~u60bab449-2475-4ad1-8c7c-f8797345c767&quot;],[&quot;^&gt;&quot;,&quot;~u60bab449-8ca8-4f3c-a09a-69289aac29fd&quot;],[&quot;^&gt;&quot;,&quot;~u60bab449-3e41-4b72-90f4-5bbff9642e80&quot;]]],536870917]],[&quot;^1=&quot;,[75,&quot;^X&quot;,&quot;Transition:&quot;,536870917]],[&quot;^1=&quot;,[75,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[75,&quot;^I&quot;,74,536870917]],[&quot;^1=&quot;,[75,&quot;^U&quot;,2,536870917]],[&quot;^1=&quot;,[75,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,1263,&quot;^1F&quot;,1278],536870917]],[&quot;^1=&quot;,[75,&quot;^13&quot;,34,536870917]],[&quot;^1=&quot;,[75,&quot;^10&quot;,73,536870917]],[&quot;^1=&quot;,[75,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;Transition:&quot;]],536870917]],[&quot;^1=&quot;,[75,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[75,&quot;^&gt;&quot;,&quot;~u60bab449-e0d6-4dfc-ba5f-b856e2a7b590&quot;,536870917]],[&quot;^1=&quot;,[76,&quot;^1?&quot;,&quot;A_transition_step_is_defined_by_the_four_element_tuple_(s-2c-_a-2c-_s-27--2c-_r)-2e-_The_transition_probability_function_P_defines_the_probability_of_transition_from_s_to_s-27-_given_an_action_a_and_obtaining_reward_r-2e-&quot;,536870917]],[&quot;^1=&quot;,[76,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[76,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[76,&quot;^X&quot;,&quot;A transition step is defined by the four element tuple $(s, a, s&apos;, r)$. The transition probability function $P$ defines the probability of transition from $s$ to $s&apos;$ given an action $a$ and obtaining reward $r$.&quot;,536870917]],[&quot;^1=&quot;,[76,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[76,&quot;^I&quot;,75,536870917]],[&quot;^1=&quot;,[76,&quot;^U&quot;,3,536870917]],[&quot;^1=&quot;,[76,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,1278,&quot;^1F&quot;,1495],536870917]],[&quot;^1=&quot;,[76,&quot;^13&quot;,34,536870917]],[&quot;^1=&quot;,[76,&quot;^10&quot;,75,536870917]],[&quot;^1=&quot;,[76,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;A transition step is defined by the four element tuple &quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;(s, a, s&apos;, r)&quot;]],[&quot;Plain&quot;,&quot;. The transition probability function &quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;P&quot;]],[&quot;Plain&quot;,&quot; defines the probability of transition from &quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;s&quot;]],[&quot;Plain&quot;,&quot; to &quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;s&apos;&quot;]],[&quot;Plain&quot;,&quot; given an action &quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;a&quot;]],[&quot;Plain&quot;,&quot; and obtaining reward &quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;r&quot;]],[&quot;Plain&quot;,&quot;.&quot;]],536870917]],[&quot;^1=&quot;,[76,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[76,&quot;^&gt;&quot;,&quot;~u60bab449-3e41-4b72-90f4-5bbff9642e80&quot;,536870917]],[&quot;^1=&quot;,[77,&quot;^1?&quot;,&quot;&quot;,536870917]],[&quot;^1=&quot;,[77,&quot;^P&quot;,[[&quot;Displayed_Math&quot;,&quot;P\\\\left(s^{\\\\prime}, r \\\\mid s, a\\\\right)=\\\\mathbb{P}\\\\left[S_{t+1}=s^{\\\\prime}, R_{t+1}=r \\\\mid S_{t}=s, A_{t}=a\\\\right]&quot;]],536870917]],[&quot;^1=&quot;,[77,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[77,&quot;^X&quot;,&quot;\\t\\t  $$P\\\\left(s^{\\\\prime}, r \\\\mid s, a\\\\right)=\\\\mathbb{P}\\\\left[S_{t+1}=s^{\\\\prime}, R_{t+1}=r \\\\mid S_{t}=s, A_{t}=a\\\\right]$$&quot;,536870917]],[&quot;^1=&quot;,[77,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[77,&quot;^I&quot;,76,536870917]],[&quot;^1=&quot;,[77,&quot;^U&quot;,3,536870917]],[&quot;^1=&quot;,[77,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,1495,&quot;^1F&quot;,1620],536870917]],[&quot;^1=&quot;,[77,&quot;^13&quot;,34,536870917]],[&quot;^1=&quot;,[77,&quot;^10&quot;,75,536870917]],[&quot;^1=&quot;,[77,&quot;^W&quot;,[],536870917]],[&quot;^1=&quot;,[77,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[77,&quot;^&gt;&quot;,&quot;~u60bab449-8ca8-4f3c-a09a-69289aac29fd&quot;,536870917]],[&quot;^1=&quot;,[78,&quot;^1?&quot;,&quot;Thus_the_state_transition_function_can_be_defined_as_a_function_of_P(s-27--2c-r-7c-s-2c-a)&quot;,536870917]],[&quot;^1=&quot;,[78,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[78,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[78,&quot;^X&quot;,&quot;Thus the state-transition function can be defined as a function of $P(s&apos;,r|s,a)$&quot;,536870917]],[&quot;^1=&quot;,[78,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[78,&quot;^I&quot;,77,536870917]],[&quot;^1=&quot;,[78,&quot;^U&quot;,3,536870917]],[&quot;^1=&quot;,[78,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,1620,&quot;^1F&quot;,1705],536870917]],[&quot;^1=&quot;,[78,&quot;^13&quot;,34,536870917]],[&quot;^1=&quot;,[78,&quot;^10&quot;,75,536870917]],[&quot;^1=&quot;,[78,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;Thus the state-transition function can be defined as a function of &quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;P(s&apos;,r|s,a)&quot;]]],536870917]],[&quot;^1=&quot;,[78,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[78,&quot;^&gt;&quot;,&quot;~u60bab449-2475-4ad1-8c7c-f8797345c767&quot;,536870917]],[&quot;^1=&quot;,[79,&quot;^1?&quot;,&quot;&quot;,536870917]],[&quot;^1=&quot;,[79,&quot;^P&quot;,[[&quot;Displayed_Math&quot;,&quot;P_{s s^{\\\\prime}}^{a}=P\\\\left(s^{\\\\prime} \\\\mid s, a\\\\right)=\\\\mathbb{P}\\\\left[S_{t+1}=s^{\\\\prime} \\\\mid S_{t}=s, A_{t}=a\\\\right]=\\\\sum_{r \\\\in \\\\mathcal{R}} P\\\\left(s^{\\\\prime}, r \\\\mid s, a\\\\right)&quot;]],536870917]],[&quot;^1=&quot;,[79,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[79,&quot;^X&quot;,&quot;\\t\\t  $$P_{s s^{\\\\prime}}^{a}=P\\\\left(s^{\\\\prime} \\\\mid s, a\\\\right)=\\\\mathbb{P}\\\\left[S_{t+1}=s^{\\\\prime} \\\\mid S_{t}=s, A_{t}=a\\\\right]=\\\\sum_{r \\\\in \\\\mathcal{R}} P\\\\left(s^{\\\\prime}, r \\\\mid s, a\\\\right)$$&quot;,536870917]],[&quot;^1=&quot;,[79,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[79,&quot;^I&quot;,78,536870917]],[&quot;^1=&quot;,[79,&quot;^U&quot;,3,536870917]],[&quot;^1=&quot;,[79,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,1705,&quot;^1F&quot;,1900],536870917]],[&quot;^1=&quot;,[79,&quot;^13&quot;,34,536870917]],[&quot;^1=&quot;,[79,&quot;^10&quot;,75,536870917]],[&quot;^1=&quot;,[79,&quot;^W&quot;,[],536870917]],[&quot;^1=&quot;,[79,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[79,&quot;^&gt;&quot;,&quot;~u60bab449-279c-41c1-87a4-bbf55a29a4af&quot;,536870917]],[&quot;^1=&quot;,[80,&quot;^1?&quot;,&quot;Known_model&quot;,536870917]],[&quot;^1=&quot;,[80,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[80,&quot;^1@&quot;,[&quot;^1A&quot;,[[&quot;^&gt;&quot;,&quot;~u60bab449-b612-4970-a2b0-23e5caea8405&quot;],[&quot;^&gt;&quot;,&quot;~u60bab449-dbfb-4f44-9477-5cbd1d1f9d38&quot;],[&quot;^&gt;&quot;,&quot;~u60bab449-1ef6-4fec-b326-6e0ed00f1573&quot;]]],536870917]],[&quot;^1=&quot;,[80,&quot;^X&quot;,&quot;Known model&quot;,536870917]],[&quot;^1=&quot;,[80,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[80,&quot;^I&quot;,73,536870917]],[&quot;^1=&quot;,[80,&quot;^U&quot;,1,536870917]],[&quot;^1=&quot;,[80,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,1900,&quot;^1F&quot;,1914],536870917]],[&quot;^1=&quot;,[80,&quot;^13&quot;,34,536870917]],[&quot;^1=&quot;,[80,&quot;^10&quot;,34,536870917]],[&quot;^1=&quot;,[80,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;Known model&quot;]],536870917]],[&quot;^1=&quot;,[80,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[80,&quot;^&gt;&quot;,&quot;~u60bab449-819c-4f92-8646-6dc2faa7ad24&quot;,536870917]],[&quot;^1=&quot;,[81,&quot;^1?&quot;,&quot;Planning_with_perfect_information&quot;,536870917]],[&quot;^1=&quot;,[81,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[81,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[81,&quot;^X&quot;,&quot;Planning with perfect information&quot;,536870917]],[&quot;^1=&quot;,[81,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[81,&quot;^I&quot;,80,536870917]],[&quot;^1=&quot;,[81,&quot;^U&quot;,2,536870917]],[&quot;^1=&quot;,[81,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,1914,&quot;^1F&quot;,1951],536870917]],[&quot;^1=&quot;,[81,&quot;^13&quot;,34,536870917]],[&quot;^1=&quot;,[81,&quot;^10&quot;,80,536870917]],[&quot;^1=&quot;,[81,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;Planning with perfect information&quot;]],536870917]],[&quot;^1=&quot;,[81,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[81,&quot;^&gt;&quot;,&quot;~u60bab449-1ef6-4fec-b326-6e0ed00f1573&quot;,536870917]],[&quot;^1=&quot;,[82,&quot;^1?&quot;,&quot;&quot;,536870917]],[&quot;^1=&quot;,[82,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[82,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[82,&quot;^X&quot;,&quot;[[Model Based Reinforcement Learning]]&quot;,536870917]],[&quot;^1=&quot;,[82,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[82,&quot;^I&quot;,81,536870917]],[&quot;^1=&quot;,[82,&quot;^U&quot;,2,536870917]],[&quot;^1=&quot;,[82,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,1951,&quot;^1F&quot;,1993],536870917]],[&quot;^1=&quot;,[82,&quot;^13&quot;,34,536870917]],[&quot;^1=&quot;,[82,&quot;^10&quot;,80,536870917]],[&quot;^1=&quot;,[82,&quot;^[&quot;,36,536870917]],[&quot;^1=&quot;,[82,&quot;^J&quot;,36,536870917]],[&quot;^1=&quot;,[82,&quot;^W&quot;,[[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[&quot;Search&quot;,&quot;Model Based Reinforcement Learning&quot;],&quot;^1H&quot;,[[&quot;Plain&quot;,&quot;&quot;]],&quot;^1I&quot;,&quot;[[Model Based Reinforcement Learning]]&quot;,&quot;^1J&quot;,&quot;&quot;]]],536870917]],[&quot;^1=&quot;,[82,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[82,&quot;^&gt;&quot;,&quot;~u60bab449-dbfb-4f44-9477-5cbd1d1f9d38&quot;,536870917]],[&quot;^1=&quot;,[83,&quot;^1?&quot;,&quot;&quot;,536870917]],[&quot;^1=&quot;,[83,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[83,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[83,&quot;^X&quot;,&quot;[[Dynamic Programming]]&quot;,536870917]],[&quot;^1=&quot;,[83,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[83,&quot;^I&quot;,82,536870917]],[&quot;^1=&quot;,[83,&quot;^U&quot;,2,536870917]],[&quot;^1=&quot;,[83,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,1993,&quot;^1F&quot;,2020],536870917]],[&quot;^1=&quot;,[83,&quot;^13&quot;,34,536870917]],[&quot;^1=&quot;,[83,&quot;^10&quot;,80,536870917]],[&quot;^1=&quot;,[83,&quot;^[&quot;,39,536870917]],[&quot;^1=&quot;,[83,&quot;^J&quot;,39,536870917]],[&quot;^1=&quot;,[83,&quot;^W&quot;,[[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[&quot;Search&quot;,&quot;Dynamic Programming&quot;],&quot;^1H&quot;,[[&quot;Plain&quot;,&quot;&quot;]],&quot;^1I&quot;,&quot;[[Dynamic Programming]]&quot;,&quot;^1J&quot;,&quot;&quot;]]],536870917]],[&quot;^1=&quot;,[83,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[83,&quot;^&gt;&quot;,&quot;~u60bab449-b612-4970-a2b0-23e5caea8405&quot;,536870917]],[&quot;^1=&quot;,[84,&quot;^1?&quot;,&quot;Unknown_model&quot;,536870917]],[&quot;^1=&quot;,[84,&quot;^P&quot;,[],536871008]],[&quot;^1=&quot;,[84,&quot;^1@&quot;,[&quot;^1A&quot;,[[&quot;^&gt;&quot;,&quot;~u60bab449-15c0-4af5-aa46-6bde8ac6a763&quot;],[&quot;^&gt;&quot;,&quot;~u60bab449-1e9a-4f4d-9dc1-a08571f135d4&quot;]]],536870917]],[&quot;^1=&quot;,[84,&quot;^X&quot;,&quot;Unknown model&quot;,536870917]],[&quot;^1=&quot;,[84,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[84,&quot;^I&quot;,80,536870917]],[&quot;^1=&quot;,[84,&quot;^U&quot;,1,536871008]],[&quot;^1=&quot;,[84,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,2020,&quot;^1F&quot;,2036],536870917]],[&quot;^1=&quot;,[84,&quot;^13&quot;,34,536870917]],[&quot;^1=&quot;,[84,&quot;^10&quot;,34,536870917]],[&quot;^1=&quot;,[84,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;Unknown model&quot;]],536871008]],[&quot;^1=&quot;,[84,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[84,&quot;^&gt;&quot;,&quot;~u60bab449-0dd0-407d-8522-6330825b782c&quot;,536870917]],[&quot;^1=&quot;,[85,&quot;^1?&quot;,&quot;Learn_the_model_and_plan&quot;,536870917]],[&quot;^1=&quot;,[85,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[85,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[85,&quot;^X&quot;,&quot;Learn the model and plan&quot;,536870917]],[&quot;^1=&quot;,[85,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[85,&quot;^I&quot;,84,536870917]],[&quot;^1=&quot;,[85,&quot;^U&quot;,2,536870917]],[&quot;^1=&quot;,[85,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,2036,&quot;^1F&quot;,2064],536870917]],[&quot;^1=&quot;,[85,&quot;^13&quot;,34,536870917]],[&quot;^1=&quot;,[85,&quot;^10&quot;,84,536870917]],[&quot;^1=&quot;,[85,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;Learn the model and plan&quot;]],536870917]],[&quot;^1=&quot;,[85,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[85,&quot;^&gt;&quot;,&quot;~u60bab449-1e9a-4f4d-9dc1-a08571f135d4&quot;,536870917]],[&quot;^1=&quot;,[86,&quot;^1?&quot;,&quot;&quot;,536870917]],[&quot;^1=&quot;,[86,&quot;^P&quot;,[],536870999]],[&quot;^1=&quot;,[86,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[86,&quot;^X&quot;,&quot;[[Model Free Reinforcement Learning]]&quot;,536870999]],[&quot;^1=&quot;,[86,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[86,&quot;^I&quot;,85,536870917]],[&quot;^1=&quot;,[86,&quot;^U&quot;,1,536870999]],[&quot;^1=&quot;,[86,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,2064,&quot;^1F&quot;,2155],536870917]],[&quot;^1=&quot;,[86,&quot;^13&quot;,34,536870917]],[&quot;^1=&quot;,[86,&quot;^10&quot;,84,536870917]],[&quot;^1=&quot;,[86,&quot;^[&quot;,27,536870999]],[&quot;^1=&quot;,[86,&quot;^[&quot;,34,536870999]],[&quot;^1=&quot;,[86,&quot;^C&quot;,[&quot;^ &quot;],536870999]],[&quot;^1=&quot;,[86,&quot;^J&quot;,27,536870999]],[&quot;^1=&quot;,[86,&quot;^W&quot;,[[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[&quot;Search&quot;,&quot;Model Free Reinforcement Learning&quot;],&quot;^1H&quot;,[[&quot;Plain&quot;,&quot;&quot;]],&quot;^1I&quot;,&quot;[[Model Free Reinforcement Learning]]&quot;,&quot;^1J&quot;,&quot;&quot;]]],536870999]],[&quot;^1=&quot;,[86,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[86,&quot;^&gt;&quot;,&quot;~u60bab449-15c0-4af5-aa46-6bde8ac6a763&quot;,536870917]],[&quot;^1=&quot;,[87,&quot;^1?&quot;,&quot;Overview&quot;,536870917]],[&quot;^1=&quot;,[87,&quot;^P&quot;,[],536870965]],[&quot;^1=&quot;,[87,&quot;^1@&quot;,[&quot;^1A&quot;,[[&quot;^&gt;&quot;,&quot;~u60bab449-af18-4d09-b5cd-c5a9d18bc777&quot;]]],536870917]],[&quot;^1=&quot;,[87,&quot;^X&quot;,&quot;Overview&quot;,536870931]],[&quot;^1=&quot;,[87,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[87,&quot;^I&quot;,102,536870965]],[&quot;^1=&quot;,[87,&quot;^U&quot;,1,536870965]],[&quot;^1=&quot;,[87,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,0,&quot;^1F&quot;,11],536870917]],[&quot;^1=&quot;,[87,&quot;^13&quot;,35,536870917]],[&quot;^1=&quot;,[87,&quot;^10&quot;,35,536870917]],[&quot;^1=&quot;,[87,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;Overview&quot;]],536870965]],[&quot;^1=&quot;,[87,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[87,&quot;^&gt;&quot;,&quot;~u60bab449-3279-4c2a-9d16-7dad1102e6f9&quot;,536870917]],[&quot;^1=&quot;,[88,&quot;^1?&quot;,&quot;Suppose_that_we_have_an_agent_living_in_an_unknown_environment_which_he_can_interact_and_earn_different_reward_or_punishment-2e-_Reinforcement_learning_is_a_process_of_this__to_achieve_high_Reward_from_the__he_is_interacting_with_by_taking_valid_actions-2e-_Like_other_machine_learning_algorithms-2c-_the_goal_of_reinforcement_learning_is_to_find_the_optimal_strategy_for_the_agent_which_will_maximize_future_(expected)_Returns&quot;,536870917]],[&quot;^1=&quot;,[88,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[88,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[88,&quot;^X&quot;,&quot;Suppose that we have an agent living in an unknown environment which he can interact and earn different reward or punishment. Reinforcement learning is a process of this [[Agent]] to achieve high [Reward](((60bab0a9-72f9-43d6-9160-34b517c50d9b))) from the [[Environment]] he is interacting with by taking valid **actions**. Like other machine learning algorithms, the goal of reinforcement learning is to find the optimal strategy for the agent which will maximize future (expected) [Returns](((60bab19a-4583-4875-a49f-c572179ae136)))&quot;,536870917]],[&quot;^1=&quot;,[88,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[88,&quot;^I&quot;,87,536870917]],[&quot;^1=&quot;,[88,&quot;^U&quot;,2,536870917]],[&quot;^1=&quot;,[88,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,11,&quot;^1F&quot;,549],536870917]],[&quot;^1=&quot;,[88,&quot;^13&quot;,35,536870917]],[&quot;^1=&quot;,[88,&quot;^10&quot;,87,536870917]],[&quot;^1=&quot;,[88,&quot;^[&quot;,23,536870917]],[&quot;^1=&quot;,[88,&quot;^[&quot;,30,536870917]],[&quot;^1=&quot;,[88,&quot;^[&quot;,32,536870917]],[&quot;^1=&quot;,[88,&quot;^[&quot;,34,536870917]],[&quot;^1=&quot;,[88,&quot;^J&quot;,23,536870917]],[&quot;^1=&quot;,[88,&quot;^J&quot;,30,536870917]],[&quot;^1=&quot;,[88,&quot;^J&quot;,32,536870917]],[&quot;^1=&quot;,[88,&quot;^J&quot;,34,536870917]],[&quot;^1=&quot;,[88,&quot;^J&quot;,49,536870917]],[&quot;^1=&quot;,[88,&quot;^J&quot;,69,536870917]],[&quot;^1=&quot;,[88,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;Suppose that we have an agent living in an unknown environment which he can interact and earn different reward or punishment. Reinforcement learning is a process of this &quot;],[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[&quot;Search&quot;,&quot;Agent&quot;],&quot;^1H&quot;,[[&quot;Plain&quot;,&quot;&quot;]],&quot;^1I&quot;,&quot;[[Agent]]&quot;,&quot;^1J&quot;,&quot;&quot;]],[&quot;Plain&quot;,&quot; to achieve high &quot;],[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[&quot;Search&quot;,&quot;((60bab0a9-72f9-43d6-9160-34b517c50d9b))&quot;],&quot;^1H&quot;,[[&quot;Plain&quot;,&quot;Reward&quot;]],&quot;^1I&quot;,&quot;[Reward](((60bab0a9-72f9-43d6-9160-34b517c50d9b)))&quot;,&quot;^1J&quot;,&quot;&quot;]],[&quot;Plain&quot;,&quot; from the &quot;],[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[&quot;Search&quot;,&quot;Environment&quot;],&quot;^1H&quot;,[[&quot;Plain&quot;,&quot;&quot;]],&quot;^1I&quot;,&quot;[[Environment]]&quot;,&quot;^1J&quot;,&quot;&quot;]],[&quot;Plain&quot;,&quot; he is interacting with by taking valid &quot;],[&quot;Emphasis&quot;,[[&quot;Bold&quot;],[[&quot;Plain&quot;,&quot;actions&quot;]]]],[&quot;Plain&quot;,&quot;. Like other machine learning algorithms, the goal of reinforcement learning is to find the optimal strategy for the agent which will maximize future (expected) &quot;],[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[&quot;Search&quot;,&quot;((60bab19a-4583-4875-a49f-c572179ae136))&quot;],&quot;^1H&quot;,[[&quot;Plain&quot;,&quot;Returns&quot;]],&quot;^1I&quot;,&quot;[Returns](((60bab19a-4583-4875-a49f-c572179ae136)))&quot;,&quot;^1J&quot;,&quot;&quot;]]],536870917]],[&quot;^1=&quot;,[88,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[88,&quot;^&gt;&quot;,&quot;~u60bab449-af18-4d09-b5cd-c5a9d18bc777&quot;,536870917]],[&quot;^1=&quot;,[89,&quot;^1?&quot;,&quot;Key_Concepts&quot;,536870917]],[&quot;^1=&quot;,[89,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[89,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[89,&quot;^X&quot;,&quot;Key Concepts&quot;,536870917]],[&quot;^1=&quot;,[89,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[89,&quot;^I&quot;,87,536870917]],[&quot;^1=&quot;,[89,&quot;^U&quot;,1,536870917]],[&quot;^1=&quot;,[89,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,549,&quot;^1F&quot;,564],536870917]],[&quot;^1=&quot;,[89,&quot;^13&quot;,35,536870917]],[&quot;^1=&quot;,[89,&quot;^10&quot;,35,536870917]],[&quot;^1=&quot;,[89,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;Key Concepts&quot;]],536870917]],[&quot;^1=&quot;,[89,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[89,&quot;^&gt;&quot;,&quot;~u60bab449-c77f-43e5-804d-aa1c961b8b2d&quot;,536870917]],[&quot;^1=&quot;,[90,&quot;^1?&quot;,&quot;&quot;,536870917]],[&quot;^1=&quot;,[90,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[90,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[90,&quot;^X&quot;,&quot;&quot;,536870917]],[&quot;^1=&quot;,[90,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[90,&quot;^I&quot;,89,536870917]],[&quot;^1=&quot;,[90,&quot;^U&quot;,1,536870917]],[&quot;^1=&quot;,[90,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,564,&quot;^1F&quot;,566],536870917]],[&quot;^1=&quot;,[90,&quot;^13&quot;,35,536870917]],[&quot;^1=&quot;,[90,&quot;^10&quot;,35,536870917]],[&quot;^1=&quot;,[90,&quot;^W&quot;,[],536870917]],[&quot;^1=&quot;,[90,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[90,&quot;^&gt;&quot;,&quot;~u60bab449-c960-46d9-a387-f9c313b3dada&quot;,536870917]],[&quot;^1=&quot;,[91,&quot;^1?&quot;,&quot;RL_algorithm_categorization-2e-png&quot;,536870917]],[&quot;^1=&quot;,[91,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[91,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[91,&quot;^X&quot;,&quot;![RL_algorithm_categorization.png](../assets/RL_algorithm_categorization_1622848297448_0.png)&quot;,536870917]],[&quot;^1=&quot;,[91,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[91,&quot;^I&quot;,90,536870917]],[&quot;^1=&quot;,[91,&quot;^U&quot;,1,536870917]],[&quot;^1=&quot;,[91,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,566,&quot;^1F&quot;,662],536870917]],[&quot;^1=&quot;,[91,&quot;^13&quot;,35,536870917]],[&quot;^1=&quot;,[91,&quot;^10&quot;,35,536870917]],[&quot;^1=&quot;,[91,&quot;^[&quot;,33,536870917]],[&quot;^1=&quot;,[91,&quot;^J&quot;,33,536870917]],[&quot;^1=&quot;,[91,&quot;^W&quot;,[[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[&quot;File&quot;,&quot;../assets/RL_algorithm_categorization_1622848297448_0.png&quot;],&quot;^1H&quot;,[[&quot;Plain&quot;,&quot;RL_algorithm_categorization.png&quot;]],&quot;^1I&quot;,&quot;![RL_algorithm_categorization.png](../assets/RL_algorithm_categorization_1622848297448_0.png)&quot;,&quot;^1J&quot;,&quot;&quot;]]],536870917]],[&quot;^1=&quot;,[91,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[91,&quot;^&gt;&quot;,&quot;~u60bab449-e39a-4aed-8751-54a5fd449e7e&quot;,536870917]],[&quot;^1=&quot;,[92,&quot;^1?&quot;,&quot;Summary_of_approaches_in_RL_based_on_whether_we_want_to_model_the_value-2c-_policy-2c-_or_the_environment-2e-_(Image_source-3a-_reproduced_from_David_Silver-e2--80--99-s_RL_course_lecture_1&quot;,536870917]],[&quot;^1=&quot;,[92,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[92,&quot;^1@&quot;,[&quot;^1A&quot;,[[&quot;^&gt;&quot;,&quot;~u60bab449-1d82-4e83-97f6-9b60d8c7c8ec&quot;],[&quot;^&gt;&quot;,&quot;~u60bab449-0369-4d63-beea-5b9b107b8f73&quot;],[&quot;^&gt;&quot;,&quot;~u60bab449-18db-4db2-bace-77a29b4e2f1c&quot;],[&quot;^&gt;&quot;,&quot;~u60bab449-3b8e-4f66-bab6-988d3e97008c&quot;]]],536870917]],[&quot;^1=&quot;,[92,&quot;^X&quot;,&quot;Summary of approaches in RL based on whether we want to model the value, policy, or the environment. (Image source: reproduced from [David Silver’s RL course lecture 1](https://www.youtube.com/watch?v=2pWv7GOvuf0&amp;feature=youtu.be)&quot;,536870917]],[&quot;^1=&quot;,[92,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[92,&quot;^I&quot;,91,536870917]],[&quot;^1=&quot;,[92,&quot;^U&quot;,1,536870917]],[&quot;^1=&quot;,[92,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,662,&quot;^1F&quot;,897],536870917]],[&quot;^1=&quot;,[92,&quot;^13&quot;,35,536870917]],[&quot;^1=&quot;,[92,&quot;^10&quot;,35,536870917]],[&quot;^1=&quot;,[92,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;Summary of approaches in RL based on whether we want to model the value, policy, or the environment. (Image source: reproduced from &quot;],[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[&quot;Complex&quot;,[&quot;^ &quot;,&quot;~:protocol&quot;,&quot;https&quot;,&quot;~:link&quot;,&quot;//www.youtube.com/watch?v=2pWv7GOvuf0&amp;feature=youtu.be&quot;]],&quot;^1H&quot;,[[&quot;Plain&quot;,&quot;David Silver’s RL course lecture 1&quot;]],&quot;^1I&quot;,&quot;[David Silver’s RL course lecture 1](https://www.youtube.com/watch?v=2pWv7GOvuf0&amp;feature=youtu.be)&quot;,&quot;^1J&quot;,&quot;&quot;]]],536870917]],[&quot;^1=&quot;,[92,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[92,&quot;^&gt;&quot;,&quot;~u60bab449-7cce-406f-a2ab-6fd0e71f9b25&quot;,536870917]],[&quot;^1=&quot;,[93,&quot;^1?&quot;,&quot;Policy&quot;,536870917]],[&quot;^1=&quot;,[93,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[93,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[93,&quot;^X&quot;,&quot;[Policy](((60bab1ac-1c32-4c47-ac87-3648dd4a905d)))&quot;,536870917]],[&quot;^1=&quot;,[93,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[93,&quot;^I&quot;,92,536870917]],[&quot;^1=&quot;,[93,&quot;^U&quot;,2,536870917]],[&quot;^1=&quot;,[93,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,897,&quot;^1F&quot;,951],536870917]],[&quot;^1=&quot;,[93,&quot;^13&quot;,35,536870917]],[&quot;^1=&quot;,[93,&quot;^10&quot;,92,536870917]],[&quot;^1=&quot;,[93,&quot;^[&quot;,29,536870917]],[&quot;^1=&quot;,[93,&quot;^J&quot;,29,536870917]],[&quot;^1=&quot;,[93,&quot;^J&quot;,53,536870917]],[&quot;^1=&quot;,[93,&quot;^W&quot;,[[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[&quot;Search&quot;,&quot;((60bab1ac-1c32-4c47-ac87-3648dd4a905d))&quot;],&quot;^1H&quot;,[[&quot;Plain&quot;,&quot;Policy&quot;]],&quot;^1I&quot;,&quot;[Policy](((60bab1ac-1c32-4c47-ac87-3648dd4a905d)))&quot;,&quot;^1J&quot;,&quot;&quot;]]],536870917]],[&quot;^1=&quot;,[93,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[93,&quot;^&gt;&quot;,&quot;~u60bab449-3b8e-4f66-bab6-988d3e97008c&quot;,536870917]],[&quot;^1=&quot;,[94,&quot;^1?&quot;,&quot;Value_Function&quot;,536870917]],[&quot;^1=&quot;,[94,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[94,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[94,&quot;^X&quot;,&quot;[Value Function](((60bab1cc-0172-486f-9cad-f43867642b45)))&quot;,536870917]],[&quot;^1=&quot;,[94,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[94,&quot;^I&quot;,93,536870917]],[&quot;^1=&quot;,[94,&quot;^U&quot;,2,536870917]],[&quot;^1=&quot;,[94,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,951,&quot;^1F&quot;,1013],536870917]],[&quot;^1=&quot;,[94,&quot;^13&quot;,35,536870917]],[&quot;^1=&quot;,[94,&quot;^10&quot;,92,536870917]],[&quot;^1=&quot;,[94,&quot;^[&quot;,28,536870917]],[&quot;^1=&quot;,[94,&quot;^J&quot;,28,536870917]],[&quot;^1=&quot;,[94,&quot;^J&quot;,59,536870917]],[&quot;^1=&quot;,[94,&quot;^W&quot;,[[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[&quot;Search&quot;,&quot;((60bab1cc-0172-486f-9cad-f43867642b45))&quot;],&quot;^1H&quot;,[[&quot;Plain&quot;,&quot;Value Function&quot;]],&quot;^1I&quot;,&quot;[Value Function](((60bab1cc-0172-486f-9cad-f43867642b45)))&quot;,&quot;^1J&quot;,&quot;&quot;]]],536870917]],[&quot;^1=&quot;,[94,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[94,&quot;^&gt;&quot;,&quot;~u60bab449-18db-4db2-bace-77a29b4e2f1c&quot;,536870917]],[&quot;^1=&quot;,[95,&quot;^1?&quot;,&quot;Reward&quot;,536870917]],[&quot;^1=&quot;,[95,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[95,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[95,&quot;^X&quot;,&quot;[Reward](((60bab0a3-2a58-4de2-9689-a1ce280de44a)))&quot;,536870917]],[&quot;^1=&quot;,[95,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[95,&quot;^I&quot;,94,536870917]],[&quot;^1=&quot;,[95,&quot;^U&quot;,2,536870917]],[&quot;^1=&quot;,[95,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,1013,&quot;^1F&quot;,1067],536870917]],[&quot;^1=&quot;,[95,&quot;^13&quot;,35,536870917]],[&quot;^1=&quot;,[95,&quot;^10&quot;,92,536870917]],[&quot;^1=&quot;,[95,&quot;^[&quot;,38,536870917]],[&quot;^1=&quot;,[95,&quot;^J&quot;,38,536870917]],[&quot;^1=&quot;,[95,&quot;^J&quot;,70,536870917]],[&quot;^1=&quot;,[95,&quot;^W&quot;,[[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[&quot;Search&quot;,&quot;((60bab0a3-2a58-4de2-9689-a1ce280de44a))&quot;],&quot;^1H&quot;,[[&quot;Plain&quot;,&quot;Reward&quot;]],&quot;^1I&quot;,&quot;[Reward](((60bab0a3-2a58-4de2-9689-a1ce280de44a)))&quot;,&quot;^1J&quot;,&quot;&quot;]]],536870917]],[&quot;^1=&quot;,[95,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[95,&quot;^&gt;&quot;,&quot;~u60bab449-0369-4d63-beea-5b9b107b8f73&quot;,536870917]],[&quot;^1=&quot;,[96,&quot;^1?&quot;,&quot;Model&quot;,536870917]],[&quot;^1=&quot;,[96,&quot;^P&quot;,[],536870917]],[&quot;^1=&quot;,[96,&quot;^1@&quot;,[&quot;^1A&quot;,[]],536870917]],[&quot;^1=&quot;,[96,&quot;^X&quot;,&quot;[Model](((60bab15b-57ca-48e8-863b-fd4c5745a2e3)))&quot;,536870917]],[&quot;^1=&quot;,[96,&quot;^T&quot;,&quot;^1B&quot;,536870917]],[&quot;^1=&quot;,[96,&quot;^I&quot;,95,536870917]],[&quot;^1=&quot;,[96,&quot;^U&quot;,2,536870917]],[&quot;^1=&quot;,[96,&quot;^R&quot;,[&quot;^ &quot;,&quot;^1C&quot;,[],&quot;^1D&quot;,[],&quot;^1E&quot;,1067,&quot;^1F&quot;,1119],536870917]],[&quot;^1=&quot;,[96,&quot;^13&quot;,35,536870917]],[&quot;^1=&quot;,[96,&quot;^10&quot;,92,536870917]],[&quot;^1=&quot;,[96,&quot;^[&quot;,37,536870917]],[&quot;^1=&quot;,[96,&quot;^J&quot;,37,536870917]],[&quot;^1=&quot;,[96,&quot;^J&quot;,74,536870917]],[&quot;^1=&quot;,[96,&quot;^W&quot;,[[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[&quot;Search&quot;,&quot;((60bab15b-57ca-48e8-863b-fd4c5745a2e3))&quot;],&quot;^1H&quot;,[[&quot;Plain&quot;,&quot;Model&quot;]],&quot;^1I&quot;,&quot;[Model](((60bab15b-57ca-48e8-863b-fd4c5745a2e3)))&quot;,&quot;^1J&quot;,&quot;&quot;]]],536870917]],[&quot;^1=&quot;,[96,&quot;^1K&quot;,true,536870917]],[&quot;^1=&quot;,[96,&quot;^&gt;&quot;,&quot;~u60bab449-1d82-4e83-97f6-9b60d8c7c8ec&quot;,536870917]],[&quot;^1=&quot;,[99,&quot;^Z&quot;,&quot;^Y&quot;,536870918]],[&quot;^1=&quot;,[101,&quot;^X&quot;,&quot;public:: true&quot;,536870960]],[&quot;^1=&quot;,[101,&quot;^T&quot;,&quot;^1B&quot;,536870960]],[&quot;^1=&quot;,[101,&quot;^I&quot;,24,536870960]],[&quot;^1=&quot;,[101,&quot;^13&quot;,24,536870960]],[&quot;^1=&quot;,[101,&quot;^10&quot;,24,536870960]],[&quot;^1=&quot;,[101,&quot;^&lt;&quot;,true,536870960]],[&quot;^1=&quot;,[101,&quot;^C&quot;,[&quot;^ &quot;,&quot;^1&gt;&quot;,true],536870960]],[&quot;^1=&quot;,[101,&quot;^W&quot;,[],536870960]],[&quot;^1=&quot;,[101,&quot;^&gt;&quot;,&quot;~u60bab54e-a747-42c8-af3b-f5c854c7e0e6&quot;,536870960]],[&quot;^1=&quot;,[102,&quot;^X&quot;,&quot;public:: true&quot;,536870965]],[&quot;^1=&quot;,[102,&quot;^T&quot;,&quot;^1B&quot;,536870965]],[&quot;^1=&quot;,[102,&quot;^I&quot;,35,536870965]],[&quot;^1=&quot;,[102,&quot;^13&quot;,35,536870965]],[&quot;^1=&quot;,[102,&quot;^10&quot;,35,536870965]],[&quot;^1=&quot;,[102,&quot;^&lt;&quot;,true,536870965]],[&quot;^1=&quot;,[102,&quot;^C&quot;,[&quot;^ &quot;,&quot;^1&gt;&quot;,true],536870965]],[&quot;^1=&quot;,[102,&quot;^W&quot;,[],536870965]],[&quot;^1=&quot;,[102,&quot;^&gt;&quot;,&quot;~u60bab55a-dab2-4423-972a-14ca1d84d7e9&quot;,536870965]],[&quot;^1=&quot;,[103,&quot;^X&quot;,&quot;public:: true&quot;,536870970]],[&quot;^1=&quot;,[103,&quot;^T&quot;,&quot;^1B&quot;,536870970]],[&quot;^1=&quot;,[103,&quot;^I&quot;,23,536870970]],[&quot;^1=&quot;,[103,&quot;^13&quot;,23,536870970]],[&quot;^1=&quot;,[103,&quot;^10&quot;,23,536870970]],[&quot;^1=&quot;,[103,&quot;^&lt;&quot;,true,536870970]],[&quot;^1=&quot;,[103,&quot;^C&quot;,[&quot;^ &quot;,&quot;^1&gt;&quot;,true],536870970]],[&quot;^1=&quot;,[103,&quot;^W&quot;,[],536870970]],[&quot;^1=&quot;,[103,&quot;^&gt;&quot;,&quot;~u60bab55e-b738-4f99-affb-b6a67f577ebe&quot;,536870970]],[&quot;^1=&quot;,[104,&quot;^X&quot;,&quot;public:: true&quot;,536870975]],[&quot;^1=&quot;,[104,&quot;^T&quot;,&quot;^1B&quot;,536870975]],[&quot;^1=&quot;,[104,&quot;^I&quot;,34,536870975]],[&quot;^1=&quot;,[104,&quot;^13&quot;,34,536870975]],[&quot;^1=&quot;,[104,&quot;^10&quot;,34,536870975]],[&quot;^1=&quot;,[104,&quot;^&lt;&quot;,true,536870975]],[&quot;^1=&quot;,[104,&quot;^C&quot;,[&quot;^ &quot;,&quot;^1&gt;&quot;,true],536870975]],[&quot;^1=&quot;,[104,&quot;^W&quot;,[],536870975]],[&quot;^1=&quot;,[104,&quot;^&gt;&quot;,&quot;~u60bab563-d1cd-4490-b7bd-fdf0dd532ff4&quot;,536870975]],[&quot;^1=&quot;,[106,&quot;^1?&quot;,&quot;Link-3a-&quot;,536871000]],[&quot;^1=&quot;,[106,&quot;^P&quot;,[],536871023]],[&quot;^1=&quot;,[106,&quot;^X&quot;,&quot;Link:&quot;,536871023]],[&quot;^1=&quot;,[106,&quot;^T&quot;,&quot;^1B&quot;,536871000]],[&quot;^1=&quot;,[106,&quot;^I&quot;,107,536871017]],[&quot;^1=&quot;,[106,&quot;^U&quot;,1,536871023]],[&quot;^1=&quot;,[106,&quot;^13&quot;,34,536871000]],[&quot;^1=&quot;,[106,&quot;^10&quot;,34,536871004]],[&quot;^1=&quot;,[106,&quot;^[&quot;,34,536871023]],[&quot;^1=&quot;,[106,&quot;^C&quot;,[&quot;^ &quot;],536871023]],[&quot;^1=&quot;,[106,&quot;^W&quot;,[[&quot;Plain&quot;,&quot;Link:&quot;]],536871023]],[&quot;^1=&quot;,[106,&quot;^1K&quot;,true,536871000]],[&quot;^1=&quot;,[106,&quot;^&gt;&quot;,&quot;~u60bab73a-d523-478b-845b-b3d697a09be1&quot;,536871000]],[&quot;^1=&quot;,[107,&quot;^1?&quot;,&quot;&quot;,536871009]],[&quot;^1=&quot;,[107,&quot;^P&quot;,[[&quot;Horizontal_Rule&quot;]],536871020]],[&quot;^1=&quot;,[107,&quot;^X&quot;,&quot;---&quot;,536871020]],[&quot;^1=&quot;,[107,&quot;^T&quot;,&quot;^1B&quot;,536871009]],[&quot;^1=&quot;,[107,&quot;^I&quot;,84,536871009]],[&quot;^1=&quot;,[107,&quot;^U&quot;,1,536871020]],[&quot;^1=&quot;,[107,&quot;^13&quot;,34,536871009]],[&quot;^1=&quot;,[107,&quot;^10&quot;,34,536871009]],[&quot;^1=&quot;,[107,&quot;^[&quot;,34,536871020]],[&quot;^1=&quot;,[107,&quot;^C&quot;,[&quot;^ &quot;],536871020]],[&quot;^1=&quot;,[107,&quot;^W&quot;,[],536871020]],[&quot;^1=&quot;,[107,&quot;^1K&quot;,true,536871009]],[&quot;^1=&quot;,[107,&quot;^&gt;&quot;,&quot;~u60bab73e-7935-49c8-84b3-baa745f184cf&quot;,536871009]],[&quot;^1=&quot;,[109,&quot;^1?&quot;,&quot;&quot;,536871024]],[&quot;^1=&quot;,[109,&quot;^P&quot;,[],536871024]],[&quot;^1=&quot;,[109,&quot;^X&quot;,&quot;[[Reinforcement Learning]]&quot;,536871024]],[&quot;^1=&quot;,[109,&quot;^T&quot;,&quot;^1B&quot;,536871024]],[&quot;^1=&quot;,[109,&quot;^I&quot;,106,536871024]],[&quot;^1=&quot;,[109,&quot;^U&quot;,1,536871024]],[&quot;^1=&quot;,[109,&quot;^13&quot;,34,536871024]],[&quot;^1=&quot;,[109,&quot;^10&quot;,34,536871024]],[&quot;^1=&quot;,[109,&quot;^[&quot;,34,536871024]],[&quot;^1=&quot;,[109,&quot;^[&quot;,35,536871024]],[&quot;^1=&quot;,[109,&quot;^C&quot;,[&quot;^ &quot;],536871024]],[&quot;^1=&quot;,[109,&quot;^J&quot;,35,536871024]],[&quot;^1=&quot;,[109,&quot;^W&quot;,[[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[&quot;Search&quot;,&quot;Reinforcement Learning&quot;],&quot;^1H&quot;,[[&quot;Plain&quot;,&quot;&quot;]],&quot;^1I&quot;,&quot;[[Reinforcement Learning]]&quot;,&quot;^1J&quot;,&quot;&quot;]]],536871024]],[&quot;^1=&quot;,[109,&quot;^1K&quot;,true,536871024]],[&quot;^1=&quot;,[109,&quot;^&gt;&quot;,&quot;~u60bab748-5bc5-4dcf-94f3-a97948b7cd64&quot;,536871024]]]]]]"</script><script>window.logseq_state="{:ui/theme \"white\", :ui/cycle-collapse :show-all, :ui/sidebar-collapsed-blocks {}, :ui/show-recent? false, :config {\"local\" {:git-pull-secs 60, :default-templates {:journals \"\"}, :macros {}, :markdown/version 2, :preferred-workflow :todo, :feature/enable-encryption? true, :commands [], :hidden [], :default-queries {:journals [{:title \"🔨 NOW\", :query [:find (pull ?h [*]) :in $ ?start ?today :where [?h :block/marker ?marker] [(contains? #{\"NOW\" \"DOING\"} ?marker)] [?h :block/page ?p] [?p :block/journal? true] [?p :block/journal-day ?d] [(>= ?d ?start)] [(<= ?d ?today)]], :inputs [:14d :today], :result-transform (fn [result] (sort-by (fn [h] (get h :block/priority \"Z\")) result)), :collapsed? false} {:title \"📅 NEXT\", :query [:find (pull ?h [*]) :in $ ?start ?next :where [?h :block/marker ?marker] [(contains? #{\"NOW\" \"LATER\" \"TODO\"} ?marker)] [?h :block/ref-pages ?p] [?p :block/journal? true] [?p :block/journal-day ?d] [(> ?d ?start)] [(< ?d ?next)]], :inputs [:today :7d-after], :collapsed? false}]}, :git-push-secs 10, :git-auto-push true, :editor/logical-outdenting? true, :ui/enable-tooltip? true}}}"</script><script type="text/javascript">// Single Page Apps for GitHub Pages
      // https://github.com/rafgraph/spa-github-pages
      // Copyright (c) 2016 Rafael Pedicini, licensed under the MIT License
      // ----------------------------------------------------------------------
      // This script checks to see if a redirect is present in the query string
      // and converts it back into the correct url and adds it to the
      // browser's history using window.history.replaceState(...),
      // which won't cause the browser to attempt to load the new url.
      // When the single page app is loaded further down in this file,
      // the correct url will be waiting in the browser's history for
      // the single page app to route accordingly.
      (function(l) {
        if (l.search) {
          var q = {};
          l.search.slice(1).split('&').forEach(function(v) {
            var a = v.split('=');
            q[a[0]] = a.slice(1).join('=').replace(/~and~/g, '&');
          });
          if (q.p !== undefined) {
            window.history.replaceState(null, null,
              l.pathname.slice(0, -1) + (q.p || '') +
              (q.q ? ('?' + q.q) : '') +
              l.hash
            );
          }
        }
      }(window.location))</script><script src="/static/js/highlight.min.js"></script><script src="/static/js/interact.min.js"></script><script src="/static/js/main.js"></script></body>